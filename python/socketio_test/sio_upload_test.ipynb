{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-upload-cell-v3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socketio\n",
    "import os\n",
    "import base64\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import threading\n",
    "from typing import Optional\n",
    "import mimetypes\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_ID = \"101\"\n",
    "SERVER_URL = \"http://localhost:5055\"\n",
    "PROJECT_NAMESPACE = f\"/project/{PROJECT_ID}\"\n",
    "\n",
    "LARGE_CSV_FILE_PATH = \"generated_cells_data_large_1gb.csv\"\n",
    "ANNDATA_FILE_PATH = \"scanpy-pbmc3k.h5ad\"\n",
    "\n",
    "# Upload parameters\n",
    "CHUNK_SIZE = 256 * 1024  # 256KB chunks\n",
    "DATASOURCE_NAME = None  # Set to None to use filename, or specify a name string\n",
    "REPLACE_DATASOURCE = True  # Set to True to overwrite if datasource with same name exists\n",
    "\n",
    "# File type to upload - change this to switch between CSV and AnnData\n",
    "UPLOAD_FILE_TYPE = \"anndata\"  # Options: \"csv\" or \"anndata\"\n",
    "\n",
    "# Retry parameters\n",
    "MAX_RETRIES = 50\n",
    "RETRY_DELAY_SECONDS = 15  # Wait time between retries\n",
    "\n",
    "# Configure logging for the client\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - SOCKETIO_CLIENT - %(levelname)s - %(message)s')\n",
    "client_logger = logging.getLogger(__name__)\n",
    "\n",
    "def detect_file_type(file_path):\n",
    "    \"\"\"Detect file type based on extension and content.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return None, None\n",
    "    \n",
    "    filename = os.path.basename(file_path).lower()\n",
    "    \n",
    "    if filename.endswith('.h5ad'):\n",
    "        return \"anndata\", \"application/x-hdf\"\n",
    "    elif filename.endswith('.csv'):\n",
    "        return \"csv\", \"text/csv\"\n",
    "    else:\n",
    "        # Try to guess based on mime type\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "        if mime_type == \"text/csv\":\n",
    "            return \"csv\", \"text/csv\"\n",
    "        else:\n",
    "            return \"unknown\", mime_type or \"application/octet-stream\"\n",
    "\n",
    "class SocketIOUploader:\n",
    "    \"\"\"\n",
    "    SocketIO-based file uploader with resumability support for CSV and AnnData files.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, server_url: str, namespace: str, file_path: str, name: Optional[str] = None, \n",
    "                 file_id: Optional[str] = None, view: str = \"default\", \n",
    "                 replace: bool = True, supplied_only: bool = False):\n",
    "        \"\"\"Initialize the SocketIO uploader.\"\"\"\n",
    "        self.server_url = server_url\n",
    "        self.namespace = namespace\n",
    "        self.file_path = file_path\n",
    "        self.file_size = os.path.getsize(file_path)\n",
    "        self.file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Auto-detect file type\n",
    "        self.file_type, self.content_type = detect_file_type(file_path)\n",
    "        client_logger.info(f\"Detected file type: {self.file_type}, content type: {self.content_type}\")\n",
    "        \n",
    "        # Set datasource name (only used for CSV files)\n",
    "        if self.file_type == \"csv\":\n",
    "            self.name = name or os.path.splitext(self.file_name)[0]\n",
    "            self.view = view\n",
    "            self.replace = replace\n",
    "            self.supplied_only = supplied_only\n",
    "        else:\n",
    "            # For AnnData files, these parameters are not needed\n",
    "            self.name = None\n",
    "            self.view = None\n",
    "            self.replace = None\n",
    "            self.supplied_only = None\n",
    "        \n",
    "        # File ID for tracking and resuming\n",
    "        self.file_id = file_id or str(uuid.uuid4())\n",
    "        client_logger.info(f\"Initialized SocketIO uploader for file: {self.file_name}, File ID: {self.file_id}\")\n",
    "        \n",
    "        # State variables\n",
    "        self.progress = 0\n",
    "        self.uploaded_bytes = 0\n",
    "        self.resume_offset = 0\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.processing_complete = False\n",
    "        self.upload_transfer_complete = False\n",
    "        self.server_will_process = False\n",
    "        self.is_resuming = False\n",
    "        self.final_result = None\n",
    "        self.upload_success = False\n",
    "        self.should_exit_processing_wait = False\n",
    "        \n",
    "        # Threading events\n",
    "        self.connection_established = threading.Event()\n",
    "        self.upload_acknowledged = threading.Event()\n",
    "        self.server_responded_to_query = threading.Event()\n",
    "        self.stop_event = threading.Event()\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # SocketIO client with more conservative settings\n",
    "        self.sio = socketio.Client(\n",
    "            logger=False, \n",
    "            engineio_logger=False,\n",
    "            reconnection=False,\n",
    "            reconnection_attempts=0\n",
    "        )\n",
    "        self._setup_event_handlers()\n",
    "        \n",
    "    def _setup_event_handlers(self):\n",
    "        \"\"\"Set up SocketIO event handlers.\"\"\"\n",
    "        \n",
    "        @self.sio.on('connect', namespace=self.namespace)\n",
    "        def on_connect():\n",
    "            client_logger.info(f\"Connected to SocketIO server at {self.server_url}{self.namespace}\")\n",
    "            self.connection_established.set()\n",
    "            \n",
    "        @self.sio.on('disconnect', namespace=self.namespace)\n",
    "        def on_disconnect():\n",
    "            client_logger.info(\"Disconnected from SocketIO server\")\n",
    "            \n",
    "        @self.sio.on('connected', namespace=self.namespace)\n",
    "        def on_connected(data):\n",
    "            client_logger.info(f\"Server connection acknowledged: {data}\")\n",
    "            \n",
    "        @self.sio.on('upload_start_ack', namespace=self.namespace)\n",
    "        def on_upload_start_ack(data):\n",
    "            client_logger.info(f\"Upload start acknowledged: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                self.upload_acknowledged.set()\n",
    "                \n",
    "        @self.sio.on('upload_resume_ack', namespace=self.namespace)\n",
    "        def on_upload_resume_ack(data):\n",
    "            client_logger.info(f\"Upload resume acknowledged: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                self.resume_offset = data.get('received_bytes', 0)\n",
    "                self.is_resuming = True\n",
    "                self.upload_acknowledged.set()\n",
    "                \n",
    "        @self.sio.on('upload_end_ack', namespace=self.namespace)\n",
    "        def on_upload_end_ack(data):\n",
    "            client_logger.info(f\"Upload end acknowledged: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                with self.lock:\n",
    "                    self.upload_transfer_complete = True\n",
    "            \n",
    "        @self.sio.on('upload_progress', namespace=self.namespace)\n",
    "        def on_upload_progress(data):\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                current_progress = data.get('progress', 0)\n",
    "                if current_progress == 0 or current_progress == 100 or current_progress % 10 == 0:\n",
    "                    if not hasattr(self, '_last_logged_progress') or current_progress > self._last_logged_progress:\n",
    "                        client_logger.info(f\"Upload progress: {current_progress}% ({data.get('received')} / {data.get('total')} bytes)\")\n",
    "                        self._last_logged_progress = current_progress\n",
    "                        \n",
    "        @self.sio.on('upload_processing_initiated', namespace=self.namespace)\n",
    "        def on_upload_processing_initiated(data):\n",
    "            client_logger.info(f\"Server initiated processing: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                with self.lock:\n",
    "                    self.processing_complete = False\n",
    "                    self.server_will_process = True\n",
    "                self.server_responded_to_query.set()\n",
    "                \n",
    "        @self.sio.on('upload_processing', namespace=self.namespace)\n",
    "        def on_upload_processing(data):\n",
    "            client_logger.info(f\"Server processing file: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                with self.lock:\n",
    "                    self.processing_complete = False\n",
    "                \n",
    "        # FIXED: Properly handle upload_success event\n",
    "        @self.sio.on('upload_success', namespace=self.namespace)\n",
    "        def on_upload_success(data):\n",
    "            client_logger.info(f\"Processing successful: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                with self.lock:\n",
    "                    self.processing_complete = True\n",
    "                    self.upload_success = True\n",
    "                    self.final_result = data\n",
    "                    self.should_exit_processing_wait = True\n",
    "                    \n",
    "        @self.sio.on('upload_error', namespace=self.namespace)\n",
    "        def on_upload_error(data):\n",
    "            client_logger.error(f\"Server error: {data}\")\n",
    "            if data.get('file_id') == self.file_id or not data.get('file_id'):\n",
    "                with self.lock:\n",
    "                    self.processing_complete = True\n",
    "                    self.upload_success = False\n",
    "                    self.final_result = data\n",
    "                    self.should_exit_processing_wait = True\n",
    "                    \n",
    "        @self.sio.on('upload_resume_info', namespace=self.namespace)\n",
    "        def on_upload_resume_info(data):\n",
    "            client_logger.info(f\"Resume info received: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                self.resume_offset = data.get('received_bytes', 0)\n",
    "                self.is_resuming = True\n",
    "                self.upload_transfer_complete = False\n",
    "                self.server_will_process = False\n",
    "                self.server_responded_to_query.set()\n",
    "                \n",
    "        @self.sio.on('upload_not_found', namespace=self.namespace)\n",
    "        def on_upload_not_found(data):\n",
    "            client_logger.info(f\"Server does not have state for file: {data}\")\n",
    "            if data.get('file_id') == self.file_id:\n",
    "                self.resume_offset = 0\n",
    "                self.is_resuming = False\n",
    "                self.upload_transfer_complete = False\n",
    "                self.server_will_process = False\n",
    "                self.server_responded_to_query.set()\n",
    "                \n",
    "        @self.sio.on('pong', namespace=self.namespace)\n",
    "        def on_pong(data):\n",
    "            client_logger.debug(\"Received pong from server\")\n",
    "            \n",
    "    def _query_upload_status(self) -> bool:\n",
    "        \"\"\"Query server for upload status. Returns True if client needs to send data.\"\"\"\n",
    "        self.server_will_process = False\n",
    "        self.server_responded_to_query.clear()\n",
    "        \n",
    "        query_msg = {\"file_id\": self.file_id}\n",
    "        client_logger.info(f\"Querying server status for file_id: {self.file_id}\")\n",
    "        \n",
    "        try:\n",
    "            self.sio.emit('upload_query', query_msg, namespace=self.namespace)\n",
    "        except Exception as e:\n",
    "            client_logger.error(f\"Failed to send query: {e}\")\n",
    "            with self.lock:\n",
    "                self.processing_complete = True\n",
    "                self.upload_success = False\n",
    "                self.final_result = {'type': 'error', 'message': f'Failed to send query: {e}'}\n",
    "            return False\n",
    "            \n",
    "        # Wait for response\n",
    "        if self.server_responded_to_query.wait(timeout=20):\n",
    "            with self.lock:\n",
    "                if self.server_will_process:\n",
    "                    client_logger.info(\"Server will handle processing. No data transfer needed.\")\n",
    "                    return False\n",
    "            client_logger.info(f\"Query processed. Resuming: {self.is_resuming}, Offset: {self.resume_offset}\")\n",
    "            return True\n",
    "        else:\n",
    "            client_logger.error(\"Timeout waiting for server response to query\")\n",
    "            self.resume_offset = 0\n",
    "            self.is_resuming = False\n",
    "            return True\n",
    "            \n",
    "    def _start_upload(self):\n",
    "        \"\"\"Send upload start message.\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Build start message based on file type\n",
    "        start_msg = {\n",
    "            \"file_id\": self.file_id,\n",
    "            \"filename\": self.file_name,\n",
    "            \"size\": self.file_size,\n",
    "            \"content_type\": self.content_type\n",
    "        }\n",
    "        \n",
    "        # Add CSV-specific parameters\n",
    "        if self.file_type == \"csv\":\n",
    "            start_msg.update({\n",
    "                \"name\": self.name,\n",
    "                \"view\": self.view,\n",
    "                \"replace\": self.replace,\n",
    "                \"supplied_only\": self.supplied_only\n",
    "            })\n",
    "        \n",
    "        client_logger.info(f\"Sending upload start for {self.file_type} file, ID {self.file_id}\")\n",
    "        self.sio.emit('upload_start', start_msg, namespace=self.namespace)\n",
    "        \n",
    "    def _send_file_chunks(self):\n",
    "        \"\"\"Send file chunks to server.\"\"\"\n",
    "        chunk_num = 0\n",
    "        bytes_sent_this_session = 0\n",
    "        client_logger.info(f\"Starting file transmission from offset {self.resume_offset}\")\n",
    "        \n",
    "        try:\n",
    "            with open(self.file_path, 'rb') as file:\n",
    "                if self.is_resuming and self.resume_offset > 0:\n",
    "                    if self.resume_offset >= self.file_size:\n",
    "                        client_logger.warning(f\"Resume offset {self.resume_offset} >= file size {self.file_size}\")\n",
    "                        self.uploaded_bytes = self.resume_offset\n",
    "                        return\n",
    "                    client_logger.info(f\"Seeking to resume offset: {self.resume_offset}\")\n",
    "                    file.seek(self.resume_offset)\n",
    "                    self.uploaded_bytes = self.resume_offset\n",
    "                else:\n",
    "                    self.uploaded_bytes = 0\n",
    "                    \n",
    "                while not self.stop_event.is_set():\n",
    "                    if self.uploaded_bytes >= self.file_size:\n",
    "                        client_logger.info(\"File transfer complete\")\n",
    "                        break\n",
    "                        \n",
    "                    chunk = file.read(CHUNK_SIZE)\n",
    "                    if not chunk:\n",
    "                        client_logger.info(\"Reached end of file\")\n",
    "                        break\n",
    "                        \n",
    "                    bytes_to_send = len(chunk)\n",
    "                    if self.uploaded_bytes + bytes_to_send > self.file_size:\n",
    "                        bytes_to_send = self.file_size - self.uploaded_bytes\n",
    "                        chunk = chunk[:bytes_to_send]\n",
    "                        \n",
    "                    if bytes_to_send <= 0:\n",
    "                        break\n",
    "                        \n",
    "                    chunk_b64 = base64.b64encode(chunk).decode('utf-8')\n",
    "                    chunk_msg = {\n",
    "                        \"file_id\": self.file_id,\n",
    "                        \"chunk_num\": chunk_num,\n",
    "                        \"data\": chunk_b64\n",
    "                    }\n",
    "                    \n",
    "                    self.sio.emit('upload_chunk', chunk_msg, namespace=self.namespace)\n",
    "                    \n",
    "                    bytes_sent_this_session += bytes_to_send\n",
    "                    self.uploaded_bytes += bytes_to_send\n",
    "                    chunk_num += 1\n",
    "                    \n",
    "                    # Small delay to prevent overwhelming the server\n",
    "                    time.sleep(0.01)\n",
    "                    \n",
    "            client_logger.info(f\"Finished sending chunks. Total bytes uploaded: {self.uploaded_bytes}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            client_logger.exception(f\"Error sending file chunks: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def _end_upload(self):\n",
    "        \"\"\"Send upload end message.\"\"\"\n",
    "        if self.uploaded_bytes >= self.file_size:\n",
    "            end_msg = {\"file_id\": self.file_id}\n",
    "            client_logger.info(f\"Sending upload end for file_id: {self.file_id}\")\n",
    "            self.sio.emit('upload_end', end_msg, namespace=self.namespace)\n",
    "        else:\n",
    "            client_logger.warning(f\"Upload incomplete ({self.uploaded_bytes}/{self.file_size})\")\n",
    "\n",
    "    def upload(self):\n",
    "        \"\"\"Main upload method with improved error handling.\"\"\"\n",
    "        client_logger.info(f\"Starting SocketIO upload process for {self.file_type} file, ID: {self.file_id}\")\n",
    "        \n",
    "        # Reset state\n",
    "        self.stop_event.clear()\n",
    "        self.processing_complete = False\n",
    "        self.upload_transfer_complete = False\n",
    "        self.server_will_process = False\n",
    "        self.upload_success = False\n",
    "        self.should_exit_processing_wait = False\n",
    "        self.final_result = None\n",
    "        self.connection_established.clear()\n",
    "        self.upload_acknowledged.clear()\n",
    "        self.server_responded_to_query.clear()\n",
    "        self._last_logged_progress = -1\n",
    "        \n",
    "        try:\n",
    "            # Ensure we're disconnected first\n",
    "            try:\n",
    "                if self.sio.connected:\n",
    "                    self.sio.disconnect()\n",
    "                time.sleep(1)  # Brief pause before reconnecting\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            # Connect to server with retries\n",
    "            connection_attempts = 3\n",
    "            for conn_attempt in range(connection_attempts):\n",
    "                try:\n",
    "                    client_logger.info(f\"Connection attempt {conn_attempt + 1}/{connection_attempts}\")\n",
    "                    self.sio.connect(\n",
    "                        self.server_url, \n",
    "                        namespaces=[self.namespace],\n",
    "                        transports=['websocket', 'polling'],\n",
    "                        wait_timeout=60\n",
    "                    )\n",
    "                    \n",
    "                    # Wait for connection with timeout\n",
    "                    if self.connection_established.wait(timeout=15):\n",
    "                        client_logger.info(\"Connection established successfully\")\n",
    "                        break\n",
    "                    else:\n",
    "                        raise Exception(\"Connection timeout\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    client_logger.warning(f\"Connection attempt {conn_attempt + 1} failed: {e}\")\n",
    "                    if conn_attempt < connection_attempts - 1:\n",
    "                        time.sleep(2)  # Wait before retry\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise Exception(f\"Failed to establish connection after {connection_attempts} attempts\")\n",
    "            \n",
    "            # Verify connection is still active\n",
    "            if not self.sio.connected:\n",
    "                raise Exception(\"Connection lost after establishment\")\n",
    "            \n",
    "            # Query status\n",
    "            proceed_with_upload = self._query_upload_status()\n",
    "            \n",
    "            if proceed_with_upload:\n",
    "                client_logger.info(\"Proceeding with file data transfer\")\n",
    "                \n",
    "                # Start upload\n",
    "                self._start_upload()\n",
    "                \n",
    "                # Wait for acknowledgment\n",
    "                if not self.upload_acknowledged.wait(timeout=15):\n",
    "                    raise Exception(\"Did not receive upload acknowledgment\")\n",
    "                    \n",
    "                # Send file chunks with connection monitoring\n",
    "                self._send_file_chunks()\n",
    "                \n",
    "                # End upload\n",
    "                if not self.stop_event.is_set() and self.uploaded_bytes >= self.file_size:\n",
    "                    self._end_upload()\n",
    "                    # Wait for upload_end_ack before proceeding\n",
    "                    end_ack_timeout = 30\n",
    "                    end_ack_start = time.time()\n",
    "                    while not self.upload_transfer_complete and not self.stop_event.is_set():\n",
    "                        if time.time() - end_ack_start > end_ack_timeout:\n",
    "                            client_logger.warning(\"Timeout waiting for upload_end_ack, assuming transfer complete\")\n",
    "                            with self.lock:\n",
    "                                self.upload_transfer_complete = True\n",
    "                            break\n",
    "                        time.sleep(0.5)\n",
    "                    \n",
    "            else:\n",
    "                with self.lock:\n",
    "                    should_wait = self.server_will_process\n",
    "                if should_wait:\n",
    "                    client_logger.info(\"Server will handle processing. Waiting for completion.\")\n",
    "                    is_waiting_for_server_processing = True\n",
    "                else:\n",
    "                    client_logger.info(\"No data transfer needed.\")\n",
    "                    return True, {'type': 'info', 'message': 'No transfer needed'}\n",
    "\n",
    "            # Wait for processing with better connection management\n",
    "            timeout_seconds = 3600  # 1 hour timeout\n",
    "            start_wait_time = time.time()\n",
    "            last_ping_time = time.time()\n",
    "            ping_interval = 30  # Send ping every 30 seconds\n",
    "            max_consecutive_connection_failures = 3\n",
    "            consecutive_failures = 0\n",
    "            \n",
    "            # Check if we need to wait for processing\n",
    "            with self.lock:\n",
    "                needs_processing_wait = (self.upload_transfer_complete or \n",
    "                                       self.server_will_process or \n",
    "                                       locals().get('is_waiting_for_server_processing', False))\n",
    "\n",
    "            client_logger.info(f\"Waiting for processing completion. needs_processing_wait: {needs_processing_wait}\")\n",
    "            client_logger.info(f\"State: upload_transfer_complete={self.upload_transfer_complete}, server_will_process={self.server_will_process}\")\n",
    "\n",
    "            while not self.should_exit_processing_wait and not self.stop_event.is_set():\n",
    "                current_time = time.time()\n",
    "                \n",
    "                # Check timeout\n",
    "                if current_time - start_wait_time > timeout_seconds:\n",
    "                    client_logger.error(f\"Timeout ({timeout_seconds}s) waiting for processing\")\n",
    "                    raise Exception(\"Client timeout waiting for completion\")\n",
    "\n",
    "                # Handle connection loss more gracefully\n",
    "                if not self.sio.connected:\n",
    "                    consecutive_failures += 1\n",
    "                    client_logger.warning(f\"Connection lost (failure {consecutive_failures}/{max_consecutive_connection_failures})\")\n",
    "                    \n",
    "                    if consecutive_failures >= max_consecutive_connection_failures:\n",
    "                        client_logger.info(\"Too many connection failures during processing wait. Assuming server is processing in background.\")\n",
    "                        # Instead of failing, we'll assume the server is processing and exit gracefully\n",
    "                        with self.lock:\n",
    "                            self.upload_success = True\n",
    "                            self.final_result = {\n",
    "                                'type': 'info', \n",
    "                                'message': 'Upload completed, server processing in background. Connection lost but upload was successful.'\n",
    "                            }\n",
    "                            self.should_exit_processing_wait = True\n",
    "                        break\n",
    "                    \n",
    "                    # Try to reconnect once\n",
    "                    try:\n",
    "                        client_logger.info(\"Attempting to reconnect to check processing status...\")\n",
    "                        self.sio.connect(\n",
    "                            self.server_url, \n",
    "                            namespaces=[self.namespace],\n",
    "                            transports=['websocket', 'polling'],\n",
    "                            wait_timeout=10\n",
    "                        )\n",
    "                        if self.connection_established.wait(timeout=5):\n",
    "                            client_logger.info(\"Reconnected successfully\")\n",
    "                            consecutive_failures = 0  # Reset failure count\n",
    "                            continue\n",
    "                        else:\n",
    "                            client_logger.warning(\"Reconnection timeout\")\n",
    "                    except Exception as e:\n",
    "                        client_logger.warning(f\"Reconnection failed: {e}\")\n",
    "                    \n",
    "                    # Wait before next attempt\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                else:\n",
    "                    consecutive_failures = 0  # Reset failure count on successful connection\n",
    "\n",
    "                # Send periodic pings to keep connection alive if we're waiting for processing\n",
    "                if needs_processing_wait and current_time - last_ping_time > ping_interval:\n",
    "                    if self.sio.connected:\n",
    "                        try:\n",
    "                            client_logger.info(\"Sending keepalive ping during processing wait\")\n",
    "                            self.sio.emit('ping', {'message': 'keepalive'}, namespace=self.namespace)\n",
    "                            last_ping_time = current_time\n",
    "                        except Exception as e:\n",
    "                            client_logger.warning(f\"Failed to send keepalive ping: {e}\")\n",
    "                    \n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Return final result\n",
    "            with self.lock:\n",
    "                success = self.upload_success\n",
    "                result = self.final_result\n",
    "            \n",
    "            if success:\n",
    "                client_logger.info(f\"Upload completed successfully: {result}\")\n",
    "            else:\n",
    "                client_logger.warning(f\"Upload failed: {result}\")\n",
    "            \n",
    "            return success, result\n",
    "            \n",
    "        except Exception as e:\n",
    "            client_logger.exception(f\"Error during upload: {e}\")\n",
    "            with self.lock:\n",
    "                if not self.processing_complete:\n",
    "                    self.processing_complete = True\n",
    "                    self.upload_success = False\n",
    "                    self.final_result = {'type': 'error', 'message': f'Upload error: {e}'}\n",
    "            return False, self.final_result\n",
    "            \n",
    "        finally:\n",
    "            try:\n",
    "                if self.sio.connected:\n",
    "                    client_logger.info(\"Disconnecting from server\")\n",
    "                    self.sio.disconnect()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    def cancel_upload(self):\n",
    "        \"\"\"Cancel the current upload.\"\"\"\n",
    "        try:\n",
    "            cancel_msg = {\"file_id\": self.file_id}\n",
    "            self.sio.emit('upload_cancel', cancel_msg, namespace=self.namespace)\n",
    "            self.stop_event.set()\n",
    "        except Exception as e:\n",
    "            client_logger.error(f\"Error cancelling upload: {e}\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def preview_csv(file_path):\n",
    "    \"\"\"Preview CSV file contents.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        client_logger.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=10)\n",
    "        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        client_logger.info(f\"CSV File: {os.path.basename(file_path)} | Size: {file_size_mb:.2f} MB\")\n",
    "        print(\"\\n--- CSV Preview (first 5 rows) ---\")\n",
    "        display(df.head())\n",
    "        print(\"----------------------------------\\n\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        client_logger.error(f\"Error previewing CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "def preview_anndata(file_path):\n",
    "    \"\"\"Preview AnnData file contents.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        client_logger.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        import scanpy as sc\n",
    "        adata = sc.read(file_path)\n",
    "        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        \n",
    "        client_logger.info(f\"AnnData File: {os.path.basename(file_path)} | Size: {file_size_mb:.2f} MB\")\n",
    "        print(\"\\n--- AnnData Preview ---\")\n",
    "        print(f\"Shape: {adata.shape}\")\n",
    "        print(f\"Variables (genes): {adata.n_vars}\")\n",
    "        print(f\"Observations (cells): {adata.n_obs}\")\n",
    "        \n",
    "        if adata.obs.shape[1] > 0:\n",
    "            print(f\"\\nObservation columns: {list(adata.obs.columns[:10])}\")\n",
    "            if len(adata.obs.columns) > 10:\n",
    "                print(f\"... and {len(adata.obs.columns) - 10} more\")\n",
    "        \n",
    "        if adata.var.shape[1] > 0:\n",
    "            print(f\"\\nVariable columns: {list(adata.var.columns[:10])}\")\n",
    "            if len(adata.var.columns) > 10:\n",
    "                print(f\"... and {len(adata.var.columns) - 10} more\")\n",
    "                \n",
    "        print(\"----------------------\\n\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        client_logger.error(\"scanpy not installed. Cannot preview AnnData files.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        client_logger.error(f\"Error previewing AnnData: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "if __name__ == \"__main__\" and \"get_ipython\" in locals():\n",
    "    print(f\"--- Starting SocketIO File Upload Script ---\")\n",
    "    print(f\"Target Server: {SERVER_URL}{PROJECT_NAMESPACE}\")\n",
    "    print(f\"Upload File Type: {UPLOAD_FILE_TYPE}\")\n",
    "\n",
    "    # Select file based on type\n",
    "    if UPLOAD_FILE_TYPE.lower() == \"csv\":\n",
    "        file_path = LARGE_CSV_FILE_PATH\n",
    "        print(f\"CSV File to Upload: {file_path}\")\n",
    "    elif UPLOAD_FILE_TYPE.lower() == \"anndata\":\n",
    "        file_path = ANNDATA_FILE_PATH\n",
    "        print(f\"AnnData File to Upload: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error: Unknown file type '{UPLOAD_FILE_TYPE}'. Use 'csv' or 'anndata'\")\n",
    "        exit()\n",
    "\n",
    "    file_id_for_upload = str(uuid.uuid4())\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"\\nERROR: File not found at {file_path}\")\n",
    "    else:\n",
    "        # Preview file based on type\n",
    "        if UPLOAD_FILE_TYPE.lower() == \"csv\":\n",
    "            if not preview_csv(file_path):\n",
    "                print(\"Failed to preview CSV file\")\n",
    "                exit()\n",
    "            ds_name = DATASOURCE_NAME or os.path.splitext(os.path.basename(file_path))[0]\n",
    "            print(f\"Using Datasource Name: {ds_name}\")\n",
    "            print(f\"Replace if exists: {REPLACE_DATASOURCE}\")\n",
    "        elif UPLOAD_FILE_TYPE.lower() == \"anndata\":\n",
    "            if not preview_anndata(file_path):\n",
    "                print(\"Failed to preview AnnData file\")\n",
    "                exit()\n",
    "            ds_name = None  # Not used for AnnData\n",
    "            print(\"AnnData files don't use datasource names - will be processed automatically\")\n",
    "        \n",
    "        overall_success = False\n",
    "        final_upload_result = None\n",
    "        \n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            client_logger.info(f\"--- Upload Attempt {attempt + 1} of {MAX_RETRIES} ---\")\n",
    "            \n",
    "            print(f\"Generated File ID for attempt {attempt + 1}: {file_id_for_upload}\")\n",
    "            \n",
    "            uploader = SocketIOUploader(\n",
    "                server_url=SERVER_URL,\n",
    "                namespace=PROJECT_NAMESPACE,\n",
    "                file_path=file_path,\n",
    "                name=ds_name,  # Only used for CSV files\n",
    "                file_id=file_id_for_upload,\n",
    "                replace=REPLACE_DATASOURCE,  # Only used for CSV files\n",
    "                supplied_only=False  # Only used for CSV files\n",
    "            )\n",
    "            \n",
    "            success, result = uploader.upload()\n",
    "            final_upload_result = result\n",
    "            \n",
    "            if success:\n",
    "                client_logger.info(f\"Upload successful! Result: {result}\")\n",
    "                overall_success = True\n",
    "                break\n",
    "            else:\n",
    "                client_logger.warning(f\"Upload attempt {attempt + 1} failed: {result}\")\n",
    "                \n",
    "                # Improved error classification for retries\n",
    "                should_retry = False\n",
    "                if result and 'message' in result:\n",
    "                    msg_lower = result['message'].lower()\n",
    "                    \n",
    "                    # Expanded list of retriable error patterns\n",
    "                    retriable_error_patterns = [\n",
    "                        'connection', 'timeout', 'websocket error', 'disconnect', \n",
    "                        'namespace', 'network', 'socket', 'broken pipe', \n",
    "                        'connection reset', 'connection refused', 'connection aborted',\n",
    "                        'bad namespace', 'not a connected namespace'\n",
    "                    ]\n",
    "                    \n",
    "                    # Success patterns - don't retry these\n",
    "                    success_patterns = [\n",
    "                        'file processed successfully', 'processing successful', 'upload successful',\n",
    "                        'server processing in background', 'anndata processed successfully'\n",
    "                    ]\n",
    "                    \n",
    "                    # Check if this is actually a success message being misclassified\n",
    "                    if any(pattern in msg_lower for pattern in success_patterns):\n",
    "                        client_logger.info(\"Success message detected, stopping retries\")\n",
    "                        overall_success = True\n",
    "                        break\n",
    "                    \n",
    "                    # Check if this is a retriable error\n",
    "                    if any(pattern in msg_lower for pattern in retriable_error_patterns):\n",
    "                        should_retry = True\n",
    "                        client_logger.info(f\"Detected retriable error: {result['message']}\")\n",
    "                    else:\n",
    "                        client_logger.warning(f\"Non-retriable error detected: {result['message']}\")\n",
    "                \n",
    "                # Retry logic\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    if should_retry:\n",
    "                        client_logger.info(f\"Retrying in {RETRY_DELAY_SECONDS} seconds... (attempt {attempt + 1}/{MAX_RETRIES})\")\n",
    "                        time.sleep(RETRY_DELAY_SECONDS)\n",
    "                    else:\n",
    "                        # Even for \"non-retriable\" errors, give it a few more tries for large files\n",
    "                        if attempt < 3:  # Allow at least 3 attempts even for \"non-retriable\" errors\n",
    "                            client_logger.info(f\"Retrying anyway for large file in {RETRY_DELAY_SECONDS} seconds...\")\n",
    "                            time.sleep(RETRY_DELAY_SECONDS)\n",
    "                        else:\n",
    "                            client_logger.error(\"Non-retriable error and max retry attempts for non-retriable reached\")\n",
    "                            break\n",
    "                else:\n",
    "                    client_logger.error(\"Max retries reached\")\n",
    "                    break\n",
    "        \n",
    "        # Final result reporting\n",
    "        if overall_success:\n",
    "            print(f\"\\n UPLOAD COMPLETED SUCCESSFULLY! \")\n",
    "            print(f\"File Type: {UPLOAD_FILE_TYPE.upper()}\")\n",
    "            print(f\"Final result: {final_upload_result}\")\n",
    "            \n",
    "            if UPLOAD_FILE_TYPE.lower() == \"csv\":\n",
    "                print(f\" CSV datasource '{ds_name}' has been added to the project\")\n",
    "            elif UPLOAD_FILE_TYPE.lower() == \"anndata\":\n",
    "                print(f\" AnnData file has been processed and converted to MDV format\")\n",
    "        else:\n",
    "            print(f\"\\n UPLOAD FAILED after {MAX_RETRIES} attempts\")\n",
    "            print(f\"File Type: {UPLOAD_FILE_TYPE.upper()}\")\n",
    "            print(f\"Final result: {final_upload_result}\")\n",
    "\n",
    "# --- Configuration Helper Functions ---\n",
    "def set_csv_upload(csv_path, datasource_name=None, replace=True):\n",
    "    \"\"\"Helper function to configure for CSV upload.\"\"\"\n",
    "    global UPLOAD_FILE_TYPE, LARGE_CSV_FILE_PATH, DATASOURCE_NAME, REPLACE_DATASOURCE\n",
    "    UPLOAD_FILE_TYPE = \"csv\"\n",
    "    LARGE_CSV_FILE_PATH = csv_path\n",
    "    DATASOURCE_NAME = datasource_name\n",
    "    REPLACE_DATASOURCE = replace\n",
    "    print(f\"Configured for CSV upload: {csv_path}\")\n",
    "\n",
    "def set_anndata_upload(anndata_path):\n",
    "    \"\"\"Helper function to configure for AnnData upload.\"\"\"\n",
    "    global UPLOAD_FILE_TYPE, ANNDATA_FILE_PATH\n",
    "    UPLOAD_FILE_TYPE = \"anndata\"\n",
    "    ANNDATA_FILE_PATH = anndata_path\n",
    "    print(f\"Configured for AnnData upload: {anndata_path}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "\"\"\"\n",
    "To use this script:\n",
    "\n",
    "1. For CSV files:\n",
    "   set_csv_upload(\"path/to/your/data.csv\", \"MyDataset\", replace=True)\n",
    "   \n",
    "2. For AnnData files:\n",
    "   set_anndata_upload(\"path/to/your/data.h5ad\")\n",
    "\n",
    "3. Then run the main execution block or set UPLOAD_FILE_TYPE manually\n",
    "\n",
    "The script will automatically detect file types and handle the appropriate upload process.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
