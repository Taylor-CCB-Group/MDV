{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation using Retrieval Augmented Generation + LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import nbformat\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import regex as re\n",
    "import datetime\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import langchain_experimental.agents.agent_toolkits.pandas.base as lp\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Can you please generate a stacked bar plot that will show the abundance of each cell state per patient, then generate a scatter plot of UMAP. Plot a dot plot and a box plot as well. Rename the final analysis variable into cell state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting keys and variables\n",
    "# .env file should have OPENAI_API_KEY\n",
    "# also currently need a key.json file with google-sheet config\n",
    "load_dotenv()\n",
    "\n",
    "FILE_URL_PATH = \"./\"\n",
    "FILE_URL_NAME = \"code_files_URL.txt\"\n",
    "\n",
    "mypath = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the Google Sheets connection\n",
    "def init_google_sheet(json_keyfile_path, sheet_name):\n",
    "    scopes = [\"https://www.googleapis.com/auth/spreadsheets\",\n",
    "             \"https://www.googleapis.com/auth/drive\"]\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scopes)\n",
    "    gc = gspread.authorize(credentials)\n",
    "    sheet = gc.open(sheet_name).sheet1  # Opens the first sheet in the spreadsheet\n",
    "    return sheet\n",
    "\n",
    "# Function to log data to the Google Sheet\n",
    "def log_to_google_sheet(sheet, context, prompt, prompt_template, response):\n",
    "    timestamp = datetime.datetime.now(datetime.UTC).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    data = [timestamp, context, prompt, prompt_template, response]\n",
    "    sheet.append_row(data)  # Appends a row with the prompt and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Google Sheets connection\n",
    "json_keyfile_path = os.path.join(mypath, \"key.json\")\n",
    "sheet_name = 'Evaluation_LLM'  # TODO: Update this with your sheet's name\n",
    "sheet = init_google_sheet(json_keyfile_path, sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance of the ChatOpenAI class with specified parameters\n",
    "# Set the temperature to 0.1 for more deterministic responses\n",
    "# Specify the model to use as \"gpt-4o\"\n",
    "\n",
    "code_llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4o\")\n",
    "\n",
    "dataframe_llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_local_repo(directory_path): #url, is_sub_dir, branch_name, project_path, access_token=f\"{GITHUB_TOKEN}\"):\n",
    "    \"\"\"\n",
    "    Crawls a local directory to retrieve file paths based on specified criteria.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the local project directory.\n",
    "\n",
    "    Returns:\n",
    "        list: List of file paths that match the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of files to ignore\n",
    "    ignore_list = ['__init__.py', 'pbmc3k_tutorial.ipynb', 'pbmc3k_tutorial.py']\n",
    "\n",
    "    # Initialize an empty list to store file paths\n",
    "    files = []\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, file_names in os.walk(directory_path):\n",
    "        # Skip hidden directories (those starting with '.')\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        for file_name in file_names:\n",
    "            # Check if the file meets the criteria for inclusion\n",
    "            if file_name not in ignore_list and (file_name.endswith('.py') or file_name.endswith('.ipynb')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                files.append(file_path)\n",
    "\n",
    "    # Return the list of collected file paths\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl the local directory to get a list of relevant file paths\n",
    "local_directory_path = \"../test_projects/\"#TAURUS_examples\"\n",
    "code_files_paths = crawl_local_repo(local_directory_path)\n",
    "\n",
    "# Write the list of file paths to a specified text file\n",
    "with open(FILE_URL_PATH + FILE_URL_NAME, 'w') as f:\n",
    "    # Iterate through the list of file paths and write each one to the file\n",
    "    for item in code_files_paths:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the Python code from a .ipynb (Jupyter Notebook) file from the local filesystem\n",
    "def extract_python_code_from_ipynb(local_file_path, cell_type=\"code\"):\n",
    "    # Read the notebook content from the local file\n",
    "    with open(local_file_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = f.read()\n",
    "\n",
    "    # Parse the notebook content using nbformat\n",
    "    notebook = nbformat.reads(notebook_content, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "    # Initialize a variable to store the extracted Python code\n",
    "    python_code = None\n",
    "\n",
    "    # Iterate over the cells in the notebook\n",
    "    for cell in notebook.cells:\n",
    "        # Check if the cell type matches the specified type\n",
    "        if cell.cell_type == cell_type:\n",
    "            # Append the cell's source code to the python_code variable\n",
    "            if not python_code:\n",
    "                python_code = cell.source\n",
    "            else:\n",
    "                python_code += \"\\n\" + cell.source\n",
    "\n",
    "    # Return the extracted Python code\n",
    "    return python_code\n",
    "\n",
    "# Extracts the Python code from a .py file from the local filesystem\n",
    "def extract_python_code_from_py(local_file_path):\n",
    "    # Read the Python file from the local file system\n",
    "    with open(local_file_path, 'r', encoding='utf-8') as f:\n",
    "        python_code = f.read()\n",
    "\n",
    "    # Return the extracted Python code\n",
    "    return python_code\n",
    "\n",
    "# Read the list of file paths from the specified text file\n",
    "with open(FILE_URL_PATH + FILE_URL_NAME) as f:\n",
    "    code_files_paths = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the extracted code documents\n",
    "code_strings = []\n",
    "\n",
    "# Iterate over the list of file URLs\n",
    "for i in range(0, len(code_files_paths)):\n",
    "    # Check if the file URL ends with \".py\"\n",
    "    if code_files_paths[i].endswith(\".py\"):\n",
    "        # Extract the Python code from the .py file\n",
    "        content = extract_python_code_from_py(code_files_paths[i])\n",
    "        # Create a Document object with the extracted content and metadata\n",
    "        doc = Document(page_content=content, metadata={\"url\": code_files_paths[i], \"file_index\": i})\n",
    "        # Append the Document object to the code_strings list\n",
    "        code_strings.append(doc)\n",
    "        # Check if the file URL ends with \".py\"\n",
    "    elif code_files_paths[i].endswith(\".ipynb\"):\n",
    "        # Extract the Python code from the .py file\n",
    "        content_ipynb = extract_python_code_from_ipynb(code_files_paths[i])\n",
    "        # Create a Document object with the extracted content and metadata\n",
    "        doc_ipynb = Document(page_content=content_ipynb, metadata={\"url\": code_files_paths[i], \"file_index\": i})\n",
    "        # Append the Document object to the code_strings list\n",
    "        code_strings.append(doc_ipynb)\n",
    "\n",
    "# Uncomment to display the first document in the code_strings list\n",
    "#code_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text splitter for chunking the code strings\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,  # Specify the language as Python\n",
    "    chunk_size=20000,           # Set the chunk size to 1500 characters\n",
    "    chunk_overlap=2000          # Set the chunk overlap to 150 characters\n",
    ")\n",
    "\n",
    "# Split the code documents into chunks using the text splitter\n",
    "texts = text_splitter.split_documents(code_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of queries per minute (QPM) for embedding requests\n",
    "EMBEDDING_QPM = 100\n",
    "\n",
    "# Set the number of batches for processing embeddings\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "\n",
    "# Initialize an instance of the OpenAIEmbeddings class\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"  # Specify the model to use for generating embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index from the embedded code chunks\n",
    "# Use FAISS (Facebook AI Similarity Search) to create a searchable index\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the retriever from the FAISS index\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",      # Specify the search type as \"similarity\"\n",
    "    search_kwargs={\"k\": 5},        # Set search parameters, in this case, return the top 5 results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_question = \"Create a heatmap plot of the localisation status vs the UTR length\"\n",
    "#user_question = input(\"What would you like to ask the LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_data = os.path.join(mypath, \"sample_data/data_cells.csv\")\n",
    "#df = pd.read_csv(path_to_data)\n",
    "#df['leiden'] = df['leiden'].apply(str)\n",
    "\n",
    "\n",
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\",)\n",
    "cells_df = pd.DataFrame(adata.obs)\n",
    "cells_df.name = 'cells'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_short = df#.dropna().iloc[:2,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:283: UserWarning: Received additional kwargs {'handle_parse_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo address the question, we need to perform the following steps:\n",
      "\n",
      "1. **Identify the data asked for in the question:**\n",
      "   - The question asks for a stacked bar plot showing the abundance of each cell state per patient.\n",
      "   - It also asks for a scatter plot of UMAP, a dot plot, and a box plot.\n",
      "   - Finally, it asks to rename the final analysis variable to \"cell state\".\n",
      "\n",
      "2. **Find the relevant column names in the DataFrame:**\n",
      "   - For the stacked bar plot, we need the columns related to \"cell state\" and \"Patient\".\n",
      "   - For the scatter plot of UMAP, we need UMAP coordinates, which are not explicitly mentioned in the provided DataFrame snippet. We need to check if there are columns related to UMAP.\n",
      "   - For the dot plot and box plot, we need to determine which variables are relevant based on the context, but typically these plots involve numerical data.\n",
      "   - The final analysis variable to be renamed to \"cell state\" is not clear from the provided snippet, so we need to determine which variable this refers to.\n",
      "\n",
      "3. **Provide the relevant column names in a list:**\n",
      "\n",
      "Let's start by examining the DataFrame to identify the necessary columns for each plot type. \n",
      "\n",
      "Action: Use the Python shell to inspect the DataFrame columns and identify the relevant ones.\n",
      "Action Input: `df.columns`\u001b[0mUse the Python shell to inspect the DataFrame columns and identify the relevant ones. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mTo identify the relevant columns for the plots and renaming task, we need to inspect the DataFrame's columns. Let's do that.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: `df.columns.tolist()`\u001b[0m\u001b[36;1m\u001b[1;3m['sample_id', 'doublet_scores', 'predicted_doublets', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rp', 'pct_counts_rp', 'total_counts_hb', 'pct_counts_hb', 'total_counts_ig', 'pct_counts_ig', 'S_score', 'G2M_score', 'phase', 'Disease', 'Patient', 'Site', 'sub_bucket', 'cell state', 'Treatment', 'MM_scaled', 'Inflammation', 'Remission']\u001b[0m\u001b[32;1m\u001b[1;3mWe have identified the columns in the DataFrame. Now, let's determine the relevant columns for each task:\n",
      "\n",
      "1. **Stacked Bar Plot:**\n",
      "   - We need the columns related to \"cell state\" and \"Patient\".\n",
      "   - Relevant columns: `['cell state', 'Patient']`\n",
      "\n",
      "2. **Scatter Plot of UMAP:**\n",
      "   - UMAP coordinates are not present in the provided columns. We cannot generate a UMAP scatter plot without these coordinates.\n",
      "\n",
      "3. **Dot Plot and Box Plot:**\n",
      "   - These plots typically involve numerical data. We can choose relevant numerical columns based on the context or interest.\n",
      "   - Potential numerical columns: `['doublet_scores', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rp', 'pct_counts_rp', 'total_counts_hb', 'pct_counts_hb', 'total_counts_ig', 'pct_counts_ig', 'S_score', 'G2M_score', 'MM_scaled']`\n",
      "\n",
      "4. **Renaming the Final Analysis Variable:**\n",
      "   - The question asks to rename the final analysis variable to \"cell state\". However, it is unclear which variable this refers to. If it refers to a column not shown, we need more context.\n",
      "\n",
      "Final Answer:\n",
      "- Relevant columns for stacked bar plot: `['cell state', 'Patient']`\n",
      "- UMAP coordinates are not available in the DataFrame.\n",
      "- Potential numerical columns for dot plot and box plot: `['doublet_scores', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rp', 'pct_counts_rp', 'total_counts_hb', 'pct_counts_hb', 'total_counts_ig', 'pct_counts_ig', 'S_score', 'G2M_score', 'MM_scaled']`\n",
      "- More context is needed to rename the final analysis variable to \"cell state\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = lp.create_pandas_dataframe_agent(\n",
    "    dataframe_llm, cells_df, verbose=True, handle_parse_errors=True, allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Based on the question asked and the CSV, please perform the following steps:\n",
    "\n",
    "1. Identify the data asked for in the question.\n",
    "2. Based on step 1, find the relevant column names in the CSV based on the information identified earlier in the question asked regarding data.\n",
    "3. Provide the relevant column names from step 2 in a list.\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = prompt + \"\\nQuestion: \" + user_question\n",
    "\n",
    "# the agent might raise an error. Sometimes repeating the same prompt helps...\n",
    "final_answer = agent.invoke(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_RAG = \"\"\" \n",
    "\n",
    "Context: {context}]\n",
    "\n",
    "The collection of Python scripts provided in the context, is designed to generate various types of data visualizations \n",
    "using the mdvtools library. Each script focuses on a specific type of plot and follows a common structure that includes loading \n",
    "data from a CSV file, creating a plot using specific parameters, and serving the visualization through an MDV project. \n",
    "\n",
    "All scripts in the context share a common workflow:\n",
    "\n",
    "Setup: Define the project path, data path, and view name, the project path should always be: project_path = os.path.expanduser('~/mdv/project')\n",
    "Plot function definition: Define the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) using a function in the same way as the context.\n",
    "Project Creation: Initialize an MDVProject instance using the method: MDVProject(project_path, delete_existing=True).\n",
    "Data Loading: Load data from the specified CSV file into a pandas DataFrame using the load_data(path) function.\n",
    "Data adding: Add the data source to the project using the method: project.add_datasource(data_path, data).\n",
    "Plot Creation: Create the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) and define the plot paramaters in the same way as in the context.\n",
    "Data Conversion: Convert the plot data to JSON format for integration with the MDV project using the convert_plot_to_json(plot) function.\n",
    "Serving: Configure the project view, set it to editable, and serve the project using the .set_view(view_name, plot_view), .set_editable(True) and .serve() methods.\n",
    "\n",
    "You are a top-class Python developer. Based on the question: {question}, decide which script from the context {context} is more relevant to the question: {question} and update the script to address the question.\n",
    "If no script is relevant, guided by the context generate a new script. \n",
    "This list \"\"\" + final_answer['output'] + \"\"\" specifies the names of the data fields that need to be plotted, for example in the params field. Get the structure of params definition from the context.\n",
    "The data should be loaded in the same way as in this notebook, in this case the lines of code to be used are below: \n",
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\",)\n",
    "cells_df = pd.DataFrame(adata.obs)\n",
    "cells_df.name = 'cells' \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#The plot you should create is the same as the plot created in the context. Specify the parameters according to the respective files in the context for each plot type. DO NOT add any parameters that have not been defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_RAG = \"\"\" You can only generate python code based on the provided context. If a response cannot be formed strictly using the context, politely say you need more information to generate the plot.\n",
    "\n",
    "# Context: {context}]\n",
    "\n",
    "# The collection of Python scripts provided in the context, is designed to generate various types of data visualizations \n",
    "# using the mdvtools library. Each script focuses on a specific type of plot and follows a common structure that includes loading \n",
    "# data from a CSV file, creating a plot using specific parameters, and serving the visualization through an MDV project. \n",
    "\n",
    "# All scripts in the context share a common workflow:\n",
    "\n",
    "# Setup: Define the project path, data path, and view name, the project path should always be: project_path = os.path.expanduser('~/mdv/project')\n",
    "# Plot function definition: Define the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) using a function in the same way as the context.\n",
    "# Project Creation: Initialize an MDVProject instance using the method: MDVProject(project_path, delete_existing=True).\n",
    "# Data Loading: Load data from the specified CSV file into a pandas DataFrame using the load_data(path) function.\n",
    "# Data adding: Add the data source to the project using the method: project.add_datasource(data_path, data).\n",
    "# Plot Creation: Create the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) and define the plot paramaters in the same way as in the context.\n",
    "# Data Conversion: Convert the plot data to JSON format for integration with the MDV project using the convert_plot_to_json(plot) function.\n",
    "# Serving: Configure the project view, set it to editable, and serve the project using the .set_view(view_name, plot_view), .set_editable(True) and .serve() methods.\n",
    "\n",
    "# You are a top-class Python developer. Generate a Python script following the workflow detailed above and use exactly the same lines of code as the scripts in the context. \n",
    "# The data should be loaded from a csv provided, the path to the csv is given by: \"\"\" + path_to_data + \"\"\" \n",
    "# This list \"\"\" + final_answer['output'] + \"\"\" specifies the names of the data fields that need to be plotted, for example in the params field. Get the structure of params definition from the context. \n",
    "# The question: {question} specifies the plot required. \n",
    "# \"\"\"\n",
    "\n",
    "# #The plot you should create is the same as the plot created in the context. Specify the parameters according to the respective files in the context for each plot type. DO NOT add any parameters that have not been defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate object using the defined RAG prompt\n",
    "prompt_RAG_template = PromptTemplate(\n",
    "    template=prompt_RAG,          # Specify the template string\n",
    "    input_variables=[\"context\", \"question\"]  # Define the input variables for the template\n",
    ")\n",
    "\n",
    "# Initialize a RetrievalQA chain using the specified language model, prompt template, and retriever\n",
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm=code_llm,                 # Specify the language model to use\n",
    "    prompt=prompt_RAG_template,   # Use the defined prompt template\n",
    "    retriever=retriever,          # Use the initialized retriever for context retrieval\n",
    "    return_source_documents=True  # Configure the chain to return source documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the context for the question (this should be retrieved by the retriever, but showing as an example)\n",
    "context = retriever\n",
    "\n",
    "# Invoke the QA chain with the query and context\n",
    "output = qa_chain.invoke({\"context\": context, \"query\": user_question})\n",
    "result = output[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('To address the question, we need to create a script that generates a stacked '\n",
      " 'bar plot showing the abundance of each cell state per patient, a scatter '\n",
      " \"plot of UMAP, a dot plot, and a box plot. We'll also rename the \"\n",
      " '\"final_analysis\" variable to \"cell state\". Based on the context provided, '\n",
      " \"here's how you can achieve this:\\n\"\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'import os\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'import scanpy as sc\\n'\n",
      " 'import numpy as np\\n'\n",
      " 'import json\\n'\n",
      " 'from mdvtools.mdvproject import MDVProject\\n'\n",
      " 'from mdvtools.charts.stacked_row_plot import StackedRowChart\\n'\n",
      " 'from mdvtools.charts.scatter_plot import ScatterPlot\\n'\n",
      " 'from mdvtools.charts.dot_plot import DotPlot\\n'\n",
      " 'from mdvtools.charts.abundance_box_plot import AbundanceBoxPlot\\n'\n",
      " '\\n'\n",
      " 'def create_stacked_row_plot(title, params, size, position, legend_display, '\n",
      " 'xaxis_properties, yaxis_properties):\\n'\n",
      " '    plot = StackedRowChart(\\n'\n",
      " '        title=title,\\n'\n",
      " '        params=params,\\n'\n",
      " '        size=size,\\n'\n",
      " '        position=position\\n'\n",
      " '    )\\n'\n",
      " '    plot.set_color_legend(legend_display)\\n'\n",
      " '    plot.set_axis_properties(\"x\", xaxis_properties)\\n'\n",
      " '    plot.set_axis_properties(\"y\", yaxis_properties)\\n'\n",
      " '    return plot\\n'\n",
      " '\\n'\n",
      " 'def create_scatter_plot(title, params, size, position, color, '\n",
      " 'x_axis_settings, y_axis_settings):\\n'\n",
      " '    plot = ScatterPlot(\\n'\n",
      " '        title=title,\\n'\n",
      " '        params=params,\\n'\n",
      " '        size=size,\\n'\n",
      " '        position=position\\n'\n",
      " '    )\\n'\n",
      " '    plot.set_color_by(color)\\n'\n",
      " '    plot.set_axis_properties(\"x\", x_axis_settings)\\n'\n",
      " '    plot.set_axis_properties(\"y\", y_axis_settings)\\n'\n",
      " '    return plot\\n'\n",
      " '\\n'\n",
      " 'def create_dot_plot(title, params, size, position):\\n'\n",
      " '    plot = DotPlot(\\n'\n",
      " '        title=title,\\n'\n",
      " '        params=params,\\n'\n",
      " '        size=size,\\n'\n",
      " '        position=position\\n'\n",
      " '    )\\n'\n",
      " '    plot.set_axis_properties(\"x\", {\"label\": \"\", \"textSize\": 13, \"tickfont\": '\n",
      " '10})\\n'\n",
      " '    plot.set_axis_properties(\"y\", {\"label\": \"\", \"textSize\": 13, \"tickfont\": '\n",
      " '10})\\n'\n",
      " '    plot.set_color_scale(log_scale=False)\\n'\n",
      " '    plot.set_color_legend(True, [40, 10])\\n'\n",
      " '    plot.set_fraction_legend(True, [0, 0])\\n'\n",
      " '    return plot\\n'\n",
      " '\\n'\n",
      " 'def create_abundance_box_plot(title, params, size, position, plot_id, '\n",
      " 'x_axis_labels, x_axis_title, y_axis_labels, y_axis_title):\\n'\n",
      " '    plot = AbundanceBoxPlot(\\n'\n",
      " '        title=title,\\n'\n",
      " '        params=params,\\n'\n",
      " '        size=size,\\n'\n",
      " '        position=position,\\n'\n",
      " '        id=plot_id\\n'\n",
      " '    )\\n'\n",
      " '    plot.set_x_axis(x_axis_labels, x_axis_title)\\n'\n",
      " '    plot.set_y_axis(y_axis_labels, y_axis_title)\\n'\n",
      " '    return plot\\n'\n",
      " '\\n'\n",
      " 'def convert_plot_to_json(plot):\\n'\n",
      " '    return json.loads(json.dumps(plot.plot_data, indent=2).replace(\"\\\\\\\\\", '\n",
      " '\"\"))\\n'\n",
      " '\\n'\n",
      " 'def main():\\n'\n",
      " \"    project_path = os.path.expanduser('~/mdv/project')\\n\"\n",
      " '    view_name = \"default\"\\n'\n",
      " '    \\n'\n",
      " '    # Load data\\n'\n",
      " '    adata = '\n",
      " 'sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\")\\n'\n",
      " '    cells_df = pd.DataFrame(adata.obs)\\n'\n",
      " \"    cells_df.name = 'cells'\\n\"\n",
      " '    \\n'\n",
      " \"    # Rename 'final_analysis' to 'cell state'\\n\"\n",
      " '    cells_df.rename(columns={\"final_analysis\": \"cell state\"}, inplace=True)\\n'\n",
      " '    \\n'\n",
      " '    # Add UMAP data to the dataframe\\n'\n",
      " '    umap_np = np.array(adata.obsm[\"X_umap\"])\\n'\n",
      " '    cells_df[\"UMAP 1\"] = umap_np[:, 0]\\n'\n",
      " '    cells_df[\"UMAP 2\"] = umap_np[:, 1]\\n'\n",
      " '    \\n'\n",
      " '    # Create project\\n'\n",
      " '    project = MDVProject(project_path, delete_existing=True)\\n'\n",
      " '    \\n'\n",
      " '    # Add datasource\\n'\n",
      " \"    project.add_datasource('cells', cells_df)\\n\"\n",
      " '    \\n'\n",
      " '    # StackedRowChart parameters\\n'\n",
      " '    stacked_title = \"Abundance of Cell States per Patient\"\\n'\n",
      " '    stacked_params = [\"cell state\", \"Patient\"]\\n'\n",
      " '    stacked_size = [792, 472]\\n'\n",
      " '    stacked_position = [10, 10]\\n'\n",
      " '    stacked_legend_display = True\\n'\n",
      " '    stacked_xaxis_properties = {\"label\": \"Patient\", \"textSize\": 13, '\n",
      " '\"tickfont\": 10}\\n'\n",
      " '    stacked_yaxis_properties = {\"label\": \"Cell State\", \"textSize\": 13, '\n",
      " '\"tickfont\": 10}\\n'\n",
      " '    \\n'\n",
      " '    # Create stacked row plot\\n'\n",
      " '    stacked_row_plot = create_stacked_row_plot(\\n'\n",
      " '        stacked_title, stacked_params, stacked_size, stacked_position, '\n",
      " 'stacked_legend_display, stacked_xaxis_properties, stacked_yaxis_properties\\n'\n",
      " '    )\\n'\n",
      " '    \\n'\n",
      " '    # ScatterPlot parameters\\n'\n",
      " '    scatter_title = \"UMAP Scatter Plot\"\\n'\n",
      " '    scatter_params = [\"UMAP 1\", \"UMAP 2\"]\\n'\n",
      " '    scatter_size = [792, 472]\\n'\n",
      " '    scatter_position = [820, 10]\\n'\n",
      " \"    scatter_color = 'cell state'\\n\"\n",
      " '    scatter_x_axis_settings = {\\'size\\': 30, \\'label\\': \"UMAP 1\", '\n",
      " \"'textsize': 13, 'tickfont': 10}\\n\"\n",
      " '    scatter_y_axis_settings = {\\'size\\': 45, \\'label\\': \"UMAP 2\", '\n",
      " \"'textsize': 13, 'tickfont': 10, 'rotate_labels': False}\\n\"\n",
      " '    \\n'\n",
      " '    # Create scatter plot\\n'\n",
      " '    scatter_plot = create_scatter_plot(\\n'\n",
      " '        scatter_title, scatter_params, scatter_size, scatter_position, '\n",
      " 'scatter_color, scatter_x_axis_settings, scatter_y_axis_settings\\n'\n",
      " '    )\\n'\n",
      " '    \\n'\n",
      " '    # DotPlot parameters\\n'\n",
      " '    dot_title = \"Gene Expression Dot Plot\"\\n'\n",
      " '    dot_params = [\"cell state\", \"n_genes_by_counts\", \"total_counts\"]\\n'\n",
      " '    dot_size = [400, 250]\\n'\n",
      " '    dot_position = [10, 500]\\n'\n",
      " '    \\n'\n",
      " '    # Create dot plot\\n'\n",
      " '    dot_plot = create_dot_plot(dot_title, dot_params, dot_size, '\n",
      " 'dot_position)\\n'\n",
      " '    \\n'\n",
      " '    # AbundanceBoxPlot parameters\\n'\n",
      " '    box_title = \"Gene Expression Box Plot\"\\n'\n",
      " '    box_params = [\"n_genes_by_counts\", \"total_counts\"]\\n'\n",
      " '    box_size = [615, 557]\\n'\n",
      " '    box_position = [500, 500]\\n'\n",
      " '    box_plot_id = \"boxPlot1\"\\n'\n",
      " '    box_x_axis_labels = [\"\"]\\n'\n",
      " '    box_x_axis_title = \"\"\\n'\n",
      " '    box_y_axis_labels = [\"Abundance\"]\\n'\n",
      " '    box_y_axis_title = \"Abundance\"\\n'\n",
      " '    \\n'\n",
      " '    # Create box plot\\n'\n",
      " '    box_plot = create_abundance_box_plot(\\n'\n",
      " '        box_title, box_params, box_size, box_position, box_plot_id, '\n",
      " 'box_x_axis_labels, box_x_axis_title, box_y_axis_labels, box_y_axis_title\\n'\n",
      " '    )\\n'\n",
      " '    \\n'\n",
      " '    # Convert plots to JSON and set view\\n'\n",
      " '    stacked_row_plot_json = convert_plot_to_json(stacked_row_plot)\\n'\n",
      " '    scatter_plot_json = convert_plot_to_json(scatter_plot)\\n'\n",
      " '    dot_plot_json = convert_plot_to_json(dot_plot)\\n'\n",
      " '    box_plot_json = convert_plot_to_json(box_plot)\\n'\n",
      " '    \\n'\n",
      " \"    view_config = {'initialCharts': {'cells': [stacked_row_plot_json, \"\n",
      " 'scatter_plot_json, dot_plot_json, box_plot_json]}}\\n'\n",
      " '    \\n'\n",
      " '    project.set_view(view_name, view_config)\\n'\n",
      " '    project.set_editable(True)\\n'\n",
      " '    project.serve()\\n'\n",
      " '\\n'\n",
      " 'if __name__ == \"__main__\":\\n'\n",
      " '    main()\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Explanation:\\n'\n",
      " '1. **Data Loading**: The script loads the data using `scanpy` and converts '\n",
      " 'it into a DataFrame.\\n'\n",
      " '2. **Renaming**: The column `final_analysis` is renamed to `cell state`.\\n'\n",
      " '3. **Plot Creation**:\\n'\n",
      " '   - **Stacked Bar Plot**: Shows the abundance of each cell state per '\n",
      " 'patient.\\n'\n",
      " '   - **Scatter Plot**: Visualizes UMAP coordinates colored by cell state.\\n'\n",
      " '   - **Dot Plot**: Displays gene expression data.\\n'\n",
      " '   - **Box Plot**: Shows the distribution of gene expression.\\n'\n",
      " '4. **Project Setup**: The script sets up an MDV project, adds the data '\n",
      " 'source, and configures the view with the created plots.\\n'\n",
      " '5. **Serving**: The project is served, making the visualizations '\n",
      " 'accessible.\\n'\n",
      " '\\n'\n",
      " 'This script should be run in an environment where the `mdvtools` library and '\n",
      " 'its dependencies are installed. Adjust the file paths and parameters as '\n",
      " 'needed for your specific dataset and requirements.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the file urls retrieved from the context \n",
    "\n",
    "context_information = output['source_documents']\n",
    "context_information_metadata = [context_information[i].metadata for i in range(len(context_information))]\n",
    "context_information_metadata_url = [context_information_metadata[i]['url'] for i in range(len(context_information_metadata))]\n",
    "context_information_metadata_name = [s[82:] for s in context_information_metadata_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_response(response):\n",
    "    \"\"\"Extracts Python code from a string response.\"\"\"\n",
    "    # Use a regex pattern to match content between triple backticks\n",
    "    code_pattern = r\"```python(.*?)```\"\n",
    "    match = re.search(code_pattern, response, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched code and strip any leading/trailing whitespaces\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "code = extract_code_from_response(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_script = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import pandas as pd\n",
      "import scanpy as sc\n",
      "import numpy as np\n",
      "import json\n",
      "from mdvtools.mdvproject import MDVProject\n",
      "from mdvtools.charts.stacked_row_plot import StackedRowChart\n",
      "from mdvtools.charts.scatter_plot import ScatterPlot\n",
      "from mdvtools.charts.dot_plot import DotPlot\n",
      "from mdvtools.charts.abundance_box_plot import AbundanceBoxPlot\n",
      "\n",
      "def create_stacked_row_plot(title, params, size, position, legend_display, xaxis_properties, yaxis_properties):\n",
      "    plot = StackedRowChart(\n",
      "        title=title,\n",
      "        params=params,\n",
      "        size=size,\n",
      "        position=position\n",
      "    )\n",
      "    plot.set_color_legend(legend_display)\n",
      "    plot.set_axis_properties(\"x\", xaxis_properties)\n",
      "    plot.set_axis_properties(\"y\", yaxis_properties)\n",
      "    return plot\n",
      "\n",
      "def create_scatter_plot(title, params, size, position, color, x_axis_settings, y_axis_settings):\n",
      "    plot = ScatterPlot(\n",
      "        title=title,\n",
      "        params=params,\n",
      "        size=size,\n",
      "        position=position\n",
      "    )\n",
      "    plot.set_color_by(color)\n",
      "    plot.set_axis_properties(\"x\", x_axis_settings)\n",
      "    plot.set_axis_properties(\"y\", y_axis_settings)\n",
      "    return plot\n",
      "\n",
      "def create_dot_plot(title, params, size, position):\n",
      "    plot = DotPlot(\n",
      "        title=title,\n",
      "        params=params,\n",
      "        size=size,\n",
      "        position=position\n",
      "    )\n",
      "    plot.set_axis_properties(\"x\", {\"label\": \"\", \"textSize\": 13, \"tickfont\": 10})\n",
      "    plot.set_axis_properties(\"y\", {\"label\": \"\", \"textSize\": 13, \"tickfont\": 10})\n",
      "    plot.set_color_scale(log_scale=False)\n",
      "    plot.set_color_legend(True, [40, 10])\n",
      "    plot.set_fraction_legend(True, [0, 0])\n",
      "    return plot\n",
      "\n",
      "def create_abundance_box_plot(title, params, size, position, plot_id, x_axis_labels, x_axis_title, y_axis_labels, y_axis_title):\n",
      "    plot = AbundanceBoxPlot(\n",
      "        title=title,\n",
      "        params=params,\n",
      "        size=size,\n",
      "        position=position,\n",
      "        id=plot_id\n",
      "    )\n",
      "    plot.set_x_axis(x_axis_labels, x_axis_title)\n",
      "    plot.set_y_axis(y_axis_labels, y_axis_title)\n",
      "    return plot\n",
      "\n",
      "def convert_plot_to_json(plot):\n",
      "    return json.loads(json.dumps(plot.plot_data, indent=2).replace(\"\\\\\", \"\"))\n",
      "\n",
      "def main():\n",
      "    project_path = os.path.expanduser('~/mdv/project')\n",
      "    view_name = \"default\"\n",
      "    \n",
      "    # Load data\n",
      "    adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\")\n",
      "    cells_df = pd.DataFrame(adata.obs)\n",
      "    cells_df.name = 'cells'\n",
      "    \n",
      "    # Rename 'final_analysis' to 'cell state'\n",
      "    cells_df.rename(columns={\"final_analysis\": \"cell state\"}, inplace=True)\n",
      "    \n",
      "    # Add UMAP data to the dataframe\n",
      "    umap_np = np.array(adata.obsm[\"X_umap\"])\n",
      "    cells_df[\"UMAP 1\"] = umap_np[:, 0]\n",
      "    cells_df[\"UMAP 2\"] = umap_np[:, 1]\n",
      "    \n",
      "    # Create project\n",
      "    project = MDVProject(project_path, delete_existing=True)\n",
      "    \n",
      "    # Add datasource\n",
      "    project.add_datasource('cells', cells_df)\n",
      "    \n",
      "    # StackedRowChart parameters\n",
      "    stacked_title = \"Abundance of Cell States per Patient\"\n",
      "    stacked_params = [\"cell state\", \"Patient\"]\n",
      "    stacked_size = [792, 472]\n",
      "    stacked_position = [10, 10]\n",
      "    stacked_legend_display = True\n",
      "    stacked_xaxis_properties = {\"label\": \"Patient\", \"textSize\": 13, \"tickfont\": 10}\n",
      "    stacked_yaxis_properties = {\"label\": \"Cell State\", \"textSize\": 13, \"tickfont\": 10}\n",
      "    \n",
      "    # Create stacked row plot\n",
      "    stacked_row_plot = create_stacked_row_plot(\n",
      "        stacked_title, stacked_params, stacked_size, stacked_position, stacked_legend_display, stacked_xaxis_properties, stacked_yaxis_properties\n",
      "    )\n",
      "    \n",
      "    # ScatterPlot parameters\n",
      "    scatter_title = \"UMAP Scatter Plot\"\n",
      "    scatter_params = [\"UMAP 1\", \"UMAP 2\"]\n",
      "    scatter_size = [792, 472]\n",
      "    scatter_position = [820, 10]\n",
      "    scatter_color = 'cell state'\n",
      "    scatter_x_axis_settings = {'size': 30, 'label': \"UMAP 1\", 'textsize': 13, 'tickfont': 10}\n",
      "    scatter_y_axis_settings = {'size': 45, 'label': \"UMAP 2\", 'textsize': 13, 'tickfont': 10, 'rotate_labels': False}\n",
      "    \n",
      "    # Create scatter plot\n",
      "    scatter_plot = create_scatter_plot(\n",
      "        scatter_title, scatter_params, scatter_size, scatter_position, scatter_color, scatter_x_axis_settings, scatter_y_axis_settings\n",
      "    )\n",
      "    \n",
      "    # DotPlot parameters\n",
      "    dot_title = \"Gene Expression Dot Plot\"\n",
      "    dot_params = [\"cell state\", \"n_genes_by_counts\", \"total_counts\"]\n",
      "    dot_size = [400, 250]\n",
      "    dot_position = [10, 500]\n",
      "    \n",
      "    # Create dot plot\n",
      "    dot_plot = create_dot_plot(dot_title, dot_params, dot_size, dot_position)\n",
      "    \n",
      "    # AbundanceBoxPlot parameters\n",
      "    box_title = \"Gene Expression Box Plot\"\n",
      "    box_params = [\"n_genes_by_counts\", \"total_counts\"]\n",
      "    box_size = [615, 557]\n",
      "    box_position = [500, 500]\n",
      "    box_plot_id = \"boxPlot1\"\n",
      "    box_x_axis_labels = [\"\"]\n",
      "    box_x_axis_title = \"\"\n",
      "    box_y_axis_labels = [\"Abundance\"]\n",
      "    box_y_axis_title = \"Abundance\"\n",
      "    \n",
      "    # Create box plot\n",
      "    box_plot = create_abundance_box_plot(\n",
      "        box_title, box_params, box_size, box_position, box_plot_id, box_x_axis_labels, box_x_axis_title, box_y_axis_labels, box_y_axis_title\n",
      "    )\n",
      "    \n",
      "    # Convert plots to JSON and set view\n",
      "    stacked_row_plot_json = convert_plot_to_json(stacked_row_plot)\n",
      "    scatter_plot_json = convert_plot_to_json(scatter_plot)\n",
      "    dot_plot_json = convert_plot_to_json(dot_plot)\n",
      "    box_plot_json = convert_plot_to_json(box_plot)\n",
      "    \n",
      "    view_config = {'initialCharts': {'cells': [stacked_row_plot_json, scatter_plot_json, dot_plot_json, box_plot_json]}}\n",
      "    \n",
      "    project.set_view(view_name, view_config)\n",
      "    project.set_editable(True)\n",
      "    project.serve()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "print(original_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_parameters(script, dataframe_path):\n",
    "    # Load the dataframe to infer the column types\n",
    "    df = pd.read_csv(dataframe_path)\n",
    "    #df['leiden'] = df['leiden'].apply(str)\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    def is_categorical(column):\n",
    "        return column in categorical_columns\n",
    "\n",
    "    def is_numerical(column):\n",
    "        return column in numerical_columns\n",
    "    \n",
    "    # Define a regex pattern to find function definitions that create BoxPlots\n",
    "    patterns = [re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)BoxPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)DotPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)AbundanceBoxPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)ViolinPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)RingChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)RowChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)StackedRowChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)HeatmapPlot\\((.*?)\\)', re.DOTALL)]\n",
    "    \n",
    "    pattern_multiline = re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)MultiLinePlot\\((.*?)\\)', re.DOTALL)\n",
    "\n",
    "    for pattern in patterns:\n",
    "        if pattern.search(script):\n",
    "            \n",
    "            # Define a regex pattern to find params and param patterns\n",
    "            pattern_param = re.compile(r'params\\s*=\\s*\\[.*?\\]|param\\s*=\\s*\".*?\"')\n",
    "            \n",
    "            def reorder_params(match_param):\n",
    "                matched_text = match_param.group(0)  # Get the entire matched text\n",
    "\n",
    "                # Extract parameter names\n",
    "                if 'params' in matched_text:\n",
    "                    param_list = re.findall(r'\\'(.*?)\\'', matched_text)\n",
    "                    param_list = re.findall(r'\\\"(.*?)\\\"', matched_text)\n",
    "                else:\n",
    "                    param_list = [re.findall(r'\\\"(.*?)\\\"', matched_text)[0]]\n",
    "                \n",
    "                # Check for the presence of categorical and numerical variables\n",
    "                has_categorical = any(is_categorical(param) for param in param_list)\n",
    "                has_numerical = any(is_numerical(param) for param in param_list)\n",
    "\n",
    "                # Add a categorical variable if none is present\n",
    "                if not has_categorical and categorical_columns:\n",
    "                    param_list.insert(0, categorical_columns[0])\n",
    "                    has_categorical = True\n",
    "\n",
    "                if len(param_list) < 2:\n",
    "                    return matched_text  # No need to reorder if there are fewer than 2 parameters\n",
    "\n",
    "                first_param = param_list[0]\n",
    "                second_param = param_list[1]\n",
    "\n",
    "                # Check the types of the parameters using the dataframe\n",
    "                #if first_param in df.columns and second_param in df.columns:\n",
    "                if has_categorical and has_numerical:\n",
    "                    if not (is_categorical(first_param) and is_numerical(second_param)):\n",
    "                        param_list[0], param_list[1] = param_list[1], param_list[0]\n",
    "\n",
    "                # Reconstruct the parameters with reordered values\n",
    "                if 'params' in matched_text:\n",
    "                    reordered_params = f\"params = ['{param_list[0]}', '{param_list[1:]}']\"\n",
    "                else:\n",
    "                    reordered_params = f'param = \"{param_list[0]}\"'\n",
    "\n",
    "                return reordered_params.replace('\\'[', ' ').replace(']\\'','')\n",
    "\n",
    "            # Substitute the matches with reordered parameters\n",
    "            modified_script = re.sub(pattern_param, reorder_params, script)\n",
    "\n",
    "            return modified_script\n",
    "\n",
    "    if pattern_multiline.search(script):\n",
    "        # Define a regex pattern to find params and param patterns\n",
    "        pattern_param = re.compile(r'params\\s*=\\s*\\[.*?\\]|param\\s*=\\s*\".*?\"')\n",
    "        \n",
    "        def reorder_params_multiline(match_param):\n",
    "            matched_text = match_param.group(0)  # Get the entire matched text\n",
    "\n",
    "            # Extract parameter names\n",
    "            if 'params' in matched_text:\n",
    "                param_list = re.findall(r'\\'(.*?)\\'', matched_text)\n",
    "                param_list = re.findall(r'\\\"(.*?)\\\"', matched_text)\n",
    "            else:\n",
    "                param_list = [re.findall(r'\\\"(.*?)\\\"', matched_text)[0]]\n",
    "            \n",
    "            # Check for the presence of categorical and numerical variables\n",
    "            has_categorical = any(is_categorical(param) for param in param_list)\n",
    "            has_numerical = any(is_numerical(param) for param in param_list)\n",
    "\n",
    "            # Add a categorical variable if none is present\n",
    "            if not has_categorical and categorical_columns:\n",
    "                param_list.insert(0, categorical_columns[0])\n",
    "                has_categorical = True\n",
    "\n",
    "            if len(param_list) < 2:\n",
    "                return matched_text  # No need to reorder if there are fewer than 2 parameters\n",
    "\n",
    "            first_param = param_list[0]\n",
    "            second_param = param_list[1]\n",
    "\n",
    "            # Check the types of the parameters using the dataframe\n",
    "            #if first_param in df.columns and second_param in df.columns:\n",
    "            if has_categorical and has_numerical:\n",
    "                if not (is_numerical(first_param) and is_categorical(second_param)):\n",
    "                    param_list[0], param_list[1] = param_list[1], param_list[0]\n",
    "\n",
    "            # Reconstruct the parameters with reordered values\n",
    "            if 'params' in matched_text:\n",
    "                reordered_params = f\"params = ['{param_list[0]}', '{param_list[1:]}']\"\n",
    "            else:\n",
    "                reordered_params = f'param = \"{param_list[0]}\"'\n",
    "\n",
    "            return reordered_params.replace('\\'[', ' ').replace(']\\'','')\n",
    "\n",
    "        # Substitute the matches with reordered parameters\n",
    "        modified_script_multiline = re.sub(pattern_param, reorder_params_multiline, script)\n",
    "\n",
    "        return modified_script_multiline\n",
    "\n",
    "        \n",
    "    return script\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the reorder transformation\n",
    "modified_script = original_script#reorder_parameters(original_script, path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_functions = \"\"\"import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sys\n",
    "import  numpy as np\n",
    "from mdvtools.mdvproject import MDVProject\n",
    "from mdvtools.charts.heatmap_plot import HeatmapPlot\n",
    "from mdvtools.charts.histogram_plot import HistogramPlot\n",
    "from mdvtools.charts.dot_plot import DotPlot\n",
    "from mdvtools.charts.box_plot import BoxPlot\n",
    "from mdvtools.charts.scatter_plot_3D import ScatterPlot3D\n",
    "from mdvtools.charts.row_chart import RowChart\n",
    "from mdvtools.charts.scatter_plot import ScatterPlot\n",
    "from mdvtools.charts.abundance_box_plot import AbundanceBoxPlot\n",
    "from mdvtools.charts.stacked_row_plot import StackedRowChart\n",
    "from mdvtools.charts.ring_chart import RingChart\n",
    "from mdvtools.charts.violin_plot import ViolinPlot\n",
    "from mdvtools.charts.multi_line_plot import MultiLinePlot\n",
    "from mdvtools.charts.pie_chart import PieChart\n",
    "\n",
    "import json \\n\n",
    "\\n\n",
    "\n",
    "def load_data(path):\n",
    "    #Load data from the specified CSV file.\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "def convert_plot_to_json(plot):\n",
    "    #Convert plot data to JSON format.\n",
    "    return json.loads(json.dumps(plot.plot_data, indent=2).replace(\"\\\\\\\\\", \"\"))\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into lines\n",
    "lines = modified_script.splitlines()\n",
    "\n",
    "# Find the starting line index\n",
    "start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('def')), None)\n",
    "\n",
    "if start_index is not None:\n",
    "    # Capture all lines starting from the first 'def'\n",
    "    captured_lines = \"\\n\".join(lines[start_index:])\n",
    "    #print(\"Captured part:\\n\", captured_lines)\n",
    "else:\n",
    "    print(\"Pattern not found\")\n",
    "\n",
    "with open(\"temp_code_3.py\", \"w\") as f:\n",
    "    f.write(packages_functions)\n",
    "    f.write(captured_lines)\n",
    "    #f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the prompt and the output of the LLM to the google sheets\n",
    "log_to_google_sheet(sheet, str(context_information_metadata_name), output['query'], prompt_RAG, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# setting keys and variables\n",
      "# Crawl the GitHub repository to get a list of relevant file URLs\n",
      "Block 'b1: GitHub repo crawling' took 6.2101 seconds\n",
      "# Initialize a text splitter for chunking the code strings\n",
      "# Split the code documents into chunks using the text splitter\n",
      "Block 'b2: Text splitter initialising' took 0.0009 seconds\n",
      "# Initialize an instance of the OpenAIEmbeddings class\n",
      "Block 'b3: Embeddings creating' took 0.0534 seconds\n",
      "# Create an index from the embedded code chunks\n",
      "# Use FAISS (Facebook AI Similarity Search) to create a searchable index\n",
      "Block 'b4: FAISS database creating' took 1.3826 seconds\n",
      "# Initialize the retriever from the FAISS index\n",
      "Block 'b5: Retriever creating' took 0.0001 seconds\n",
      "created Flask <Flask 'mdvtools.server'>\n",
      "socketio initialized\n",
      "websocket/chat enabled for \n",
      " * Serving Flask app 'mdvtools.server'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5050 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:746\u001b[0m, in \u001b[0;36mBaseWSGIServer.__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_activate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/server.py:136\u001b[0m, in \u001b[0;36mHTTPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[43msocketserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTCPServer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m host, port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py:473\u001b[0m, in \u001b[0;36mTCPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mSOL_SOCKET, socket\u001b[38;5;241m.\u001b[39mSO_REUSEPORT, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mgetsockname()\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 48] Address already in use",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2932\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2931\u001b[0m     glob, loc \u001b[38;5;241m=\u001b[39m (where \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, ))[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m-> 2932\u001b[0m     \u001b[43mpy3compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshell_futures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m status:\n\u001b[1;32m   2936\u001b[0m     \u001b[38;5;66;03m# If the call was made with 0 or None exit status (sys.exit(0)\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m     \u001b[38;5;66;03m# or sys.exit() ), don't bother showing a traceback, as both of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[38;5;66;03m# For other exit status, we show the exception unless\u001b[39;00m\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;66;03m# explicitly silenced, but only in short form.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/utils/py3compat.py:55\u001b[0m, in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m     54\u001b[0m compiler \u001b[38;5;241m=\u001b[39m compiler \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/llm/temp_code_3.py:176\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/llm/temp_code_3.py:173\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m project\u001b[38;5;241m.\u001b[39mset_editable(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 173\u001b[0m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/mdvproject.py:835\u001b[0m, in \u001b[0;36mMDVProject.serve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_app\n\u001b[0;32m--> 835\u001b[0m \u001b[43mcreate_app\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/server.py:355\u001b[0m, in \u001b[0;36mcreate_app\u001b[0;34m(project, open_browser, port, websocket, use_reloader, app, chat_fn, chat_welcome)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m## nb - uncomment this if not using ProjectBlueprint refactor...\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# app.register_blueprint(project_bp)\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# user_reloader=False, allows the server to work within jupyter\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_reloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py:889\u001b[0m, in \u001b[0;36mFlask.run\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     \u001b[43mrun_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# reset the first request information if the development server\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:1077\u001b[0m, in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWERKZEUG_SERVER_FD\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1077\u001b[0m srv \u001b[38;5;241m=\u001b[39m \u001b[43mmake_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassthrough_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m srv\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mset_inheritable(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:917\u001b[0m, in \u001b[0;36mmake_server\u001b[0;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threaded:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mThreadedWSGIServer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassthrough_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:769\u001b[0m, in \u001b[0;36mBaseWSGIServer.__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    764\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOn macOS, try disabling the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirPlay Receiver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m service\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from System Preferences -> General -> AirDrop & Handoff.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    766\u001b[0m                 file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    767\u001b[0m             )\n\u001b[0;32m--> 769\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the saved Python file. This will start a server on localhost:5050, open the browser and display the plot with the server continuing to run in the background.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_code_3.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/magics/execution.py:849\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_timing(run, nruns)\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m             \u001b[38;5;66;03m# regular execution\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m             \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m __name__save\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/magics/execution.py:834\u001b[0m, in \u001b[0;36mExecutionMagics.run.<locals>.run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m():\n\u001b[0;32m--> 834\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_ns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_ns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexit_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_ignore\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2949\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2947\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   2948\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exit_ignore:\n\u001b[0;32m-> 2949\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexception_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   2951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1190\u001b[0m ):\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1083\u001b[0m )\n\u001b[1;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "# Run the saved Python file. This will start a server on localhost:5050, open the browser and display the plot with the server continuing to run in the background.\n",
    "%run temp_code_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvjupyter",
   "language": "python",
   "name": "venvjupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
