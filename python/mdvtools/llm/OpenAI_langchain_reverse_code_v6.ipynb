{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation using Retrieval Augmented Generation + LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import nbformat\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import regex as re\n",
    "import datetime\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import langchain_experimental.agents.agent_toolkits.pandas.base as lp\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Create a gene expression plot for a gene.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting keys and variables\n",
    "# .env file should have OPENAI_API_KEY\n",
    "# also currently need a key.json file with google-sheet config\n",
    "load_dotenv()\n",
    "\n",
    "FILE_URL_PATH = \"./\"\n",
    "FILE_URL_NAME = \"code_files_URL.txt\"\n",
    "\n",
    "mypath = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the Google Sheets connection\n",
    "def init_google_sheet(json_keyfile_path, sheet_name):\n",
    "    scopes = [\"https://www.googleapis.com/auth/spreadsheets\",\n",
    "             \"https://www.googleapis.com/auth/drive\"]\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scopes)\n",
    "    gc = gspread.authorize(credentials)\n",
    "    sheet = gc.open(sheet_name).sheet1  # Opens the first sheet in the spreadsheet\n",
    "    return sheet\n",
    "\n",
    "# Function to log data to the Google Sheet\n",
    "def log_to_google_sheet(sheet, context, prompt, prompt_template, response):\n",
    "    timestamp = datetime.datetime.now(datetime.UTC).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    data = [timestamp, context, prompt, prompt_template, response]\n",
    "    sheet.append_row(data)  # Appends a row with the prompt and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Google Sheets connection\n",
    "json_keyfile_path = os.path.join(mypath, \"key.json\")\n",
    "sheet_name = 'Evaluation_LLM'  # TODO: Update this with your sheet's name\n",
    "sheet = init_google_sheet(json_keyfile_path, sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance of the ChatOpenAI class with specified parameters\n",
    "# Set the temperature to 0.1 for more deterministic responses\n",
    "# Specify the model to use as \"gpt-4o\"\n",
    "\n",
    "code_llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4o\")\n",
    "\n",
    "dataframe_llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_local_repo(directory_path): #url, is_sub_dir, branch_name, project_path, access_token=f\"{GITHUB_TOKEN}\"):\n",
    "    \"\"\"\n",
    "    Crawls a local directory to retrieve file paths based on specified criteria.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the local project directory.\n",
    "\n",
    "    Returns:\n",
    "        list: List of file paths that match the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of files to ignore\n",
    "    ignore_list = ['__init__.py', 'pbmc3k_tutorial.ipynb', 'pbmc3k_tutorial.py']\n",
    "\n",
    "    # Initialize an empty list to store file paths\n",
    "    files = []\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, file_names in os.walk(directory_path):\n",
    "        # Skip hidden directories (those starting with '.')\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        for file_name in file_names:\n",
    "            # Check if the file meets the criteria for inclusion\n",
    "            if file_name not in ignore_list and (file_name.endswith('.py') or file_name.endswith('.ipynb')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                files.append(file_path)\n",
    "\n",
    "    # Return the list of collected file paths\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl the local directory to get a list of relevant file paths\n",
    "local_directory_path = \"../test_projects/\"#TAURUS_examples\"\n",
    "code_files_paths = crawl_local_repo(local_directory_path)\n",
    "\n",
    "# Write the list of file paths to a specified text file\n",
    "with open(FILE_URL_PATH + FILE_URL_NAME, 'w') as f:\n",
    "    # Iterate through the list of file paths and write each one to the file\n",
    "    for item in code_files_paths:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the Python code from a .ipynb (Jupyter Notebook) file from the local filesystem\n",
    "def extract_python_code_from_ipynb(local_file_path, cell_type=\"code\"):\n",
    "    # Read the notebook content from the local file\n",
    "    with open(local_file_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = f.read()\n",
    "\n",
    "    # Parse the notebook content using nbformat\n",
    "    notebook = nbformat.reads(notebook_content, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "    # Initialize a variable to store the extracted Python code\n",
    "    python_code = None\n",
    "\n",
    "    # Iterate over the cells in the notebook\n",
    "    for cell in notebook.cells:\n",
    "        # Check if the cell type matches the specified type\n",
    "        if cell.cell_type == cell_type:\n",
    "            # Append the cell's source code to the python_code variable\n",
    "            if not python_code:\n",
    "                python_code = cell.source\n",
    "            else:\n",
    "                python_code += \"\\n\" + cell.source\n",
    "\n",
    "    # Return the extracted Python code\n",
    "    return python_code\n",
    "\n",
    "# Extracts the Python code from a .py file from the local filesystem\n",
    "def extract_python_code_from_py(local_file_path):\n",
    "    # Read the Python file from the local file system\n",
    "    with open(local_file_path, 'r', encoding='utf-8') as f:\n",
    "        python_code = f.read()\n",
    "\n",
    "    # Return the extracted Python code\n",
    "    return python_code\n",
    "\n",
    "# Read the list of file paths from the specified text file\n",
    "with open(FILE_URL_PATH + FILE_URL_NAME) as f:\n",
    "    code_files_paths = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the extracted code documents\n",
    "code_strings = []\n",
    "\n",
    "# Iterate over the list of file URLs\n",
    "for i in range(0, len(code_files_paths)):\n",
    "    # Check if the file URL ends with \".py\"\n",
    "    if code_files_paths[i].endswith(\".py\"):\n",
    "        # Extract the Python code from the .py file\n",
    "        content = extract_python_code_from_py(code_files_paths[i])\n",
    "        # Create a Document object with the extracted content and metadata\n",
    "        doc = Document(page_content=content, metadata={\"url\": code_files_paths[i], \"file_index\": i})\n",
    "        # Append the Document object to the code_strings list\n",
    "        code_strings.append(doc)\n",
    "        # Check if the file URL ends with \".py\"\n",
    "    elif code_files_paths[i].endswith(\".ipynb\"):\n",
    "        # Extract the Python code from the .py file\n",
    "        content_ipynb = extract_python_code_from_ipynb(code_files_paths[i])\n",
    "        # Create a Document object with the extracted content and metadata\n",
    "        doc_ipynb = Document(page_content=content_ipynb, metadata={\"url\": code_files_paths[i], \"file_index\": i})\n",
    "        # Append the Document object to the code_strings list\n",
    "        code_strings.append(doc_ipynb)\n",
    "\n",
    "# Uncomment to display the first document in the code_strings list\n",
    "#code_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text splitter for chunking the code strings\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,  # Specify the language as Python\n",
    "    chunk_size=20000,           # Set the chunk size to 1500 characters\n",
    "    chunk_overlap=2000          # Set the chunk overlap to 150 characters\n",
    ")\n",
    "\n",
    "# Split the code documents into chunks using the text splitter\n",
    "texts = text_splitter.split_documents(code_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of queries per minute (QPM) for embedding requests\n",
    "EMBEDDING_QPM = 100\n",
    "\n",
    "# Set the number of batches for processing embeddings\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "\n",
    "# Initialize an instance of the OpenAIEmbeddings class\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"  # Specify the model to use for generating embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index from the embedded code chunks\n",
    "# Use FAISS (Facebook AI Similarity Search) to create a searchable index\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the retriever from the FAISS index\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",      # Specify the search type as \"similarity\"\n",
    "    search_kwargs={\"k\": 5},        # Set search parameters, in this case, return the top 5 results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_question = \"Create a heatmap plot of the localisation status vs the UTR length\"\n",
    "#user_question = input(\"What would you like to ask the LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_data = os.path.join(mypath, \"sample_data/data_cells.csv\")\n",
    "#df = pd.read_csv(path_to_data)\n",
    "#df['leiden'] = df['leiden'].apply(str)\n",
    "\n",
    "\n",
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\",)\n",
    "cells_df = pd.DataFrame(adata.obs)\n",
    "cells_df.name = 'cells'\n",
    "\n",
    "genes_df = pd.DataFrame(adata.var)\n",
    "genes_df.name = 'genes'\n",
    "genes_df['gene_id'] = genes_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:283: UserWarning: Received additional kwargs {'handle_parse_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo create a gene expression plot for a gene, we need to identify the relevant columns from the dataframes that contain information about gene expression. Here's how we can proceed:\n",
      "\n",
      "1. **Identify the data asked for in the question**: The question asks for a gene expression plot for a gene. This implies we need data related to gene expression levels.\n",
      "\n",
      "2. **Find the relevant column names in the dataframes**:\n",
      "   - From `df1`, the columns related to gene expression might include `sample_id`, `total_counts`, `total_counts_mt`, `total_counts_rp`, `total_counts_hb`, `total_counts_ig`, etc., as these are related to counts which could be indicative of expression levels.\n",
      "   - From `df2`, the columns `feature_types`, `gene_ids-CID003352-2`, and `gene_id` are relevant as they directly relate to gene information.\n",
      "\n",
      "3. **Combine relevant column names**:\n",
      "   - From `df1`: `sample_id`, `total_counts`\n",
      "   - From `df2`: `gene_id`\n",
      "\n",
      "4. **Provide the relevant column names in a list**:\n",
      "   - Relevant columns: `['sample_id', 'total_counts', 'gene_id']`\n",
      "\n",
      "5. **If the question asks for a gene name, provide a gene name**:\n",
      "   - From `df2`, we can choose a gene name such as `MIR1302-2HG`.\n",
      "\n",
      "Now, let's list the relevant column names and a gene name:\n",
      "\n",
      "Final Answer: Relevant columns: `['sample_id', 'total_counts', 'gene_id']`, Gene name: `MIR1302-2HG`\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = lp.create_pandas_dataframe_agent(\n",
    "    dataframe_llm, [cells_df,genes_df], verbose=True, handle_parse_errors=True, allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Based on the question asked and the dataframes provided, please perform the following steps:\n",
    "\n",
    "1. Identify the data asked for in the question.\n",
    "2. Based on step 1, find the relevant column names in the dataframes provided based on the information identified earlier in the question asked regarding data.\n",
    "3. The relevant column names can be a combination from the two dataframes.\n",
    "4. Provide the relevant column names from step 2 in a list.\n",
    "5. If the question asks for a gene name, do provide a gene name in addition to the relevant columns names.\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = prompt + \"\\nQuestion: \" + user_question\n",
    "\n",
    "# the agent might raise an error. Sometimes repeating the same prompt helps...\n",
    "final_answer = agent.invoke(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_RAG = \"\"\" \n",
    "\n",
    "Context: {context}]\n",
    "\n",
    "The collection of Python scripts provided in the context, is designed to generate various types of data visualizations \n",
    "using the mdvtools library. Each script focuses on a specific type of plot and follows a common structure that includes loading \n",
    "data from a CSV file, creating a plot using specific parameters, and serving the visualization through an MDV project. \n",
    "\n",
    "All scripts in the context share a common workflow:\n",
    "\n",
    "Setup: Define the project path, data path, and view name, the project path should always be: project_path = os.path.expanduser('~/mdv/project')\n",
    "Plot function definition: Define the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) using a function in the same way as the context.\n",
    "Project Creation: Initialize an MDVProject instance using the method: MDVProject(project_path, delete_existing=True).\n",
    "Data Loading: Load data from the specified CSV file into a pandas DataFrame using the load_data(path) function.\n",
    "Data adding: Add the data source to the project using the method: project.add_datasource(data_path, data).\n",
    "Plot Creation: Create the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) and define the plot paramaters in the same way as in the context.\n",
    "Data Conversion: Convert the plot data to JSON format for integration with the MDV project using the convert_plot_to_json(plot) function.\n",
    "Serving: Configure the project view, set it to editable, and serve the project using the .set_view(view_name, plot_view), .set_editable(True) and .serve() methods.\n",
    "\n",
    "You are a top-class Python developer. Based on the question: {question}, decide which script from the context {context} is more relevant to the question: {question} and update the script to address the question.\n",
    "If no script is relevant, guided by the context generate a new script. \n",
    "This list \"\"\" + final_answer['output'] + \"\"\" specifies the names of the data fields that need to be plotted, for example in the params field. Get the structure of params definition from the context.\n",
    "The data should be loaded in the same way as in this notebook, in this case the lines of code to be used are below: \n",
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\",)\n",
    "cells_df = pd.DataFrame(adata.obs)\n",
    "cells_df.name = 'cells' \n",
    "\n",
    "If the prompt asks for a gene, make sure you load this datasource and that you create a link between the two datasets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#The plot you should create is the same as the plot created in the context. Specify the parameters according to the respective files in the context for each plot type. DO NOT add any parameters that have not been defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_RAG = \"\"\" You can only generate python code based on the provided context. If a response cannot be formed strictly using the context, politely say you need more information to generate the plot.\n",
    "\n",
    "# Context: {context}]\n",
    "\n",
    "# The collection of Python scripts provided in the context, is designed to generate various types of data visualizations \n",
    "# using the mdvtools library. Each script focuses on a specific type of plot and follows a common structure that includes loading \n",
    "# data from a CSV file, creating a plot using specific parameters, and serving the visualization through an MDV project. \n",
    "\n",
    "# All scripts in the context share a common workflow:\n",
    "\n",
    "# Setup: Define the project path, data path, and view name, the project path should always be: project_path = os.path.expanduser('~/mdv/project')\n",
    "# Plot function definition: Define the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) using a function in the same way as the context.\n",
    "# Project Creation: Initialize an MDVProject instance using the method: MDVProject(project_path, delete_existing=True).\n",
    "# Data Loading: Load data from the specified CSV file into a pandas DataFrame using the load_data(path) function.\n",
    "# Data adding: Add the data source to the project using the method: project.add_datasource(data_path, data).\n",
    "# Plot Creation: Create the respective plot (dot plot, heatmap, histogram, box plot, scatter plot, 3D scatter plot, pie/ring chart, stacked row plot) and define the plot paramaters in the same way as in the context.\n",
    "# Data Conversion: Convert the plot data to JSON format for integration with the MDV project using the convert_plot_to_json(plot) function.\n",
    "# Serving: Configure the project view, set it to editable, and serve the project using the .set_view(view_name, plot_view), .set_editable(True) and .serve() methods.\n",
    "\n",
    "# You are a top-class Python developer. Generate a Python script following the workflow detailed above and use exactly the same lines of code as the scripts in the context. \n",
    "# The data should be loaded from a csv provided, the path to the csv is given by: \"\"\" + path_to_data + \"\"\" \n",
    "# This list \"\"\" + final_answer['output'] + \"\"\" specifies the names of the data fields that need to be plotted, for example in the params field. Get the structure of params definition from the context. \n",
    "# The question: {question} specifies the plot required. \n",
    "# \"\"\"\n",
    "\n",
    "# #The plot you should create is the same as the plot created in the context. Specify the parameters according to the respective files in the context for each plot type. DO NOT add any parameters that have not been defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate object using the defined RAG prompt\n",
    "prompt_RAG_template = PromptTemplate(\n",
    "    template=prompt_RAG,          # Specify the template string\n",
    "    input_variables=[\"context\", \"question\"]  # Define the input variables for the template\n",
    ")\n",
    "\n",
    "# Initialize a RetrievalQA chain using the specified language model, prompt template, and retriever\n",
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm=code_llm,                 # Specify the language model to use\n",
    "    prompt=prompt_RAG_template,   # Use the defined prompt template\n",
    "    retriever=retriever,          # Use the initialized retriever for context retrieval\n",
    "    return_source_documents=True  # Configure the chain to return source documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the context for the question (this should be retrieved by the retriever, but showing as an example)\n",
    "context = retriever\n",
    "\n",
    "# Invoke the QA chain with the query and context\n",
    "output = qa_chain.invoke({\"context\": context, \"query\": user_question})\n",
    "result = output[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('To create a gene expression plot for a specific gene, we can utilize the '\n",
      " 'script that focuses on creating a box plot for gene expression. This script '\n",
      " 'is relevant because it already includes the functionality to create a box '\n",
      " 'plot for gene expression data, which can be adapted to plot the expression '\n",
      " 'of a specific gene across different conditions or samples.\\n'\n",
      " '\\n'\n",
      " \"Here's how you can update the script to address the question, using the \"\n",
      " 'relevant columns and gene name provided:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'import os\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'import scanpy as sc\\n'\n",
      " 'import sys\\n'\n",
      " 'import json\\n'\n",
      " 'from mdvtools.mdvproject import MDVProject\\n'\n",
      " 'from mdvtools.charts.box_plot import BoxPlot\\n'\n",
      " '\\n'\n",
      " 'def create_box_plot(title, params, size, position):\\n'\n",
      " '    \"\"\"Create and configure a BoxPlot instance with the given '\n",
      " 'parameters.\"\"\"\\n'\n",
      " '    plot = BoxPlot(\\n'\n",
      " '        title=title,\\n'\n",
      " '        params=params,\\n'\n",
      " '        size=size,\\n'\n",
      " '        position=position\\n'\n",
      " '    )\\n'\n",
      " '    return plot\\n'\n",
      " '\\n'\n",
      " 'def convert_plot_to_json(plot):\\n'\n",
      " '    \"\"\"Convert plot data to JSON format.\"\"\"\\n'\n",
      " '    return json.loads(json.dumps(plot.plot_data, '\n",
      " 'indent=2).replace(\"\\\\\\\\\\\\\\\\\", \"\"))\\n'\n",
      " '\\n'\n",
      " 'def main():\\n'\n",
      " '    \"\"\"Main function to create the project and serve it.\"\"\"\\n'\n",
      " '    # Constants\\n'\n",
      " \"    project_path = os.path.expanduser('~/mdv/project')\\n\"\n",
      " '    view_name = \"default\"\\n'\n",
      " '    \\n'\n",
      " '    # Load data using scanpy\\n'\n",
      " '    adata = '\n",
      " 'sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\")\\n'\n",
      " '    cells_df = pd.DataFrame(adata.obs)\\n'\n",
      " \"    cells_df.name = 'cells'\\n\"\n",
      " '    \\n'\n",
      " '    genes_df = pd.DataFrame(adata.var)\\n'\n",
      " \"    genes_df.name = 'genes'\\n\"\n",
      " \"    genes_df['gene_id'] = genes_df.index\\n\"\n",
      " '\\n'\n",
      " \"    # Rename 'final_analysis' to 'cell state'\\n\"\n",
      " '    cells_df.rename(columns={\"final_analysis\": \"cell state\"}, inplace=True)\\n'\n",
      " '    \\n'\n",
      " '    # Create project\\n'\n",
      " '    project = MDVProject(project_path, delete_existing=True)\\n'\n",
      " '    \\n'\n",
      " '    # Add datasource\\n'\n",
      " \"    project.add_datasource('cells', cells_df)\\n\"\n",
      " \"    project.add_datasource('genes', genes_df)\\n\"\n",
      " '    \\n'\n",
      " '    # Create a link between the two datasets\\n'\n",
      " '    project.add_rows_as_columns_link(\"cells\", \"genes\", \"gene_id\", \"Gene '\n",
      " 'Expression\")\\n'\n",
      " '    project.add_rows_as_columns_subgroup(\"cells\", \"genes\", \"Gene '\n",
      " 'expression\", adata.X.toarray())\\n'\n",
      " '    \\n'\n",
      " '    # BoxPlot parameters for the specific gene \"MIR1302-2HG\"\\n'\n",
      " '    gene_name = \"MIR1302-2HG\"\\n'\n",
      " '    box_title = f\"Gene expression for {gene_name} per Sample\"\\n'\n",
      " '    box_params = [\"sample_id\", f\"Gene expression|{gene_name}(Gene '\n",
      " 'expression)|{genes_df.index.get_loc(gene_name)}\"]\\n'\n",
      " '    box_size = [792, 472]\\n'\n",
      " '    box_position = [10, 10]\\n'\n",
      " '    \\n'\n",
      " '    # Create plot\\n'\n",
      " '    plot = create_box_plot(box_title, box_params, box_size, box_position)\\n'\n",
      " '    \\n'\n",
      " '    # Convert plot to JSON and set view\\n'\n",
      " '    boxplot_chart_json = convert_plot_to_json(plot)\\n'\n",
      " \"    boxplot_view = {'initialCharts': {'cells': [boxplot_chart_json]}}\\n\"\n",
      " '    \\n'\n",
      " '    project.set_view(view_name, boxplot_view)\\n'\n",
      " '    project.set_editable(True)\\n'\n",
      " '    project.serve()\\n'\n",
      " '\\n'\n",
      " 'if __name__ == \"__main__\":\\n'\n",
      " '    main()\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '### Key Changes:\\n'\n",
      " '- **Data Loading**: The script loads the data using `scanpy` and creates '\n",
      " 'dataframes for cells and genes.\\n'\n",
      " '- **Gene Expression Plot**: A box plot is created for the gene '\n",
      " '\"MIR1302-2HG\", showing its expression across different samples '\n",
      " '(`sample_id`).\\n'\n",
      " '- **Linking Datasets**: The script creates a link between the cells and '\n",
      " 'genes datasets to enable gene expression visualization.\\n'\n",
      " '- **Box Plot Parameters**: The `box_params` are set to use `sample_id` and '\n",
      " 'the specific gene expression data for \"MIR1302-2HG\".\\n'\n",
      " '\\n'\n",
      " 'This script will generate a box plot showing the expression of the gene '\n",
      " '\"MIR1302-2HG\" across different samples, using the specified columns and data '\n",
      " 'structure.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the file urls retrieved from the context \n",
    "\n",
    "context_information = output['source_documents']\n",
    "context_information_metadata = [context_information[i].metadata for i in range(len(context_information))]\n",
    "context_information_metadata_url = [context_information_metadata[i]['url'] for i in range(len(context_information_metadata))]\n",
    "context_information_metadata_name = [s[82:] for s in context_information_metadata_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_response(response):\n",
    "    \"\"\"Extracts Python code from a string response.\"\"\"\n",
    "    # Use a regex pattern to match content between triple backticks\n",
    "    code_pattern = r\"```python(.*?)```\"\n",
    "    match = re.search(code_pattern, response, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched code and strip any leading/trailing whitespaces\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "code = extract_code_from_response(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_script = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import pandas as pd\n",
      "import scanpy as sc\n",
      "import sys\n",
      "import json\n",
      "from mdvtools.mdvproject import MDVProject\n",
      "from mdvtools.charts.box_plot import BoxPlot\n",
      "\n",
      "def create_box_plot(title, params, size, position):\n",
      "    \"\"\"Create and configure a BoxPlot instance with the given parameters.\"\"\"\n",
      "    plot = BoxPlot(\n",
      "        title=title,\n",
      "        params=params,\n",
      "        size=size,\n",
      "        position=position\n",
      "    )\n",
      "    return plot\n",
      "\n",
      "def convert_plot_to_json(plot):\n",
      "    \"\"\"Convert plot data to JSON format.\"\"\"\n",
      "    return json.loads(json.dumps(plot.plot_data, indent=2).replace(\"\\\\\\\\\", \"\"))\n",
      "\n",
      "def main():\n",
      "    \"\"\"Main function to create the project and serve it.\"\"\"\n",
      "    # Constants\n",
      "    project_path = os.path.expanduser('~/mdv/project')\n",
      "    view_name = \"default\"\n",
      "    \n",
      "    # Load data using scanpy\n",
      "    adata = sc.read_h5ad(\"../../../../../Documents/TAURUS_data/bcell_viz_ready_revised.h5ad\")\n",
      "    cells_df = pd.DataFrame(adata.obs)\n",
      "    cells_df.name = 'cells'\n",
      "    \n",
      "    genes_df = pd.DataFrame(adata.var)\n",
      "    genes_df.name = 'genes'\n",
      "    genes_df['gene_id'] = genes_df.index\n",
      "\n",
      "    # Rename 'final_analysis' to 'cell state'\n",
      "    cells_df.rename(columns={\"final_analysis\": \"cell state\"}, inplace=True)\n",
      "    \n",
      "    # Create project\n",
      "    project = MDVProject(project_path, delete_existing=True)\n",
      "    \n",
      "    # Add datasource\n",
      "    project.add_datasource('cells', cells_df)\n",
      "    project.add_datasource('genes', genes_df)\n",
      "    \n",
      "    # Create a link between the two datasets\n",
      "    project.add_rows_as_columns_link(\"cells\", \"genes\", \"gene_id\", \"Gene Expression\")\n",
      "    project.add_rows_as_columns_subgroup(\"cells\", \"genes\", \"Gene expression\", adata.X.toarray())\n",
      "    \n",
      "    # BoxPlot parameters for the specific gene \"MIR1302-2HG\"\n",
      "    gene_name = \"MIR1302-2HG\"\n",
      "    box_title = f\"Gene expression for {gene_name} per Sample\"\n",
      "    box_params = [\"sample_id\", f\"Gene expression|{gene_name}(Gene expression)|{genes_df.index.get_loc(gene_name)}\"]\n",
      "    box_size = [792, 472]\n",
      "    box_position = [10, 10]\n",
      "    \n",
      "    # Create plot\n",
      "    plot = create_box_plot(box_title, box_params, box_size, box_position)\n",
      "    \n",
      "    # Convert plot to JSON and set view\n",
      "    boxplot_chart_json = convert_plot_to_json(plot)\n",
      "    boxplot_view = {'initialCharts': {'cells': [boxplot_chart_json]}}\n",
      "    \n",
      "    project.set_view(view_name, boxplot_view)\n",
      "    project.set_editable(True)\n",
      "    project.serve()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "print(original_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_parameters(script, dataframe_path):\n",
    "    # Load the dataframe to infer the column types\n",
    "    df = pd.read_csv(dataframe_path)\n",
    "    #df['leiden'] = df['leiden'].apply(str)\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    def is_categorical(column):\n",
    "        return column in categorical_columns\n",
    "\n",
    "    def is_numerical(column):\n",
    "        return column in numerical_columns\n",
    "    \n",
    "    # Define a regex pattern to find function definitions that create BoxPlots\n",
    "    patterns = [re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)BoxPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)DotPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)AbundanceBoxPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)ViolinPlot\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)RingChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)RowChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)StackedRowChart\\((.*?)\\)', re.DOTALL),\n",
    "                re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)HeatmapPlot\\((.*?)\\)', re.DOTALL)]\n",
    "    \n",
    "    pattern_multiline = re.compile(r'def\\s+(\\w*)\\s*\\((.*?)\\):\\s*\\n(.*?)MultiLinePlot\\((.*?)\\)', re.DOTALL)\n",
    "\n",
    "    for pattern in patterns:\n",
    "        if pattern.search(script):\n",
    "            \n",
    "            # Define a regex pattern to find params and param patterns\n",
    "            pattern_param = re.compile(r'params\\s*=\\s*\\[.*?\\]|param\\s*=\\s*\".*?\"')\n",
    "            \n",
    "            def reorder_params(match_param):\n",
    "                matched_text = match_param.group(0)  # Get the entire matched text\n",
    "\n",
    "                # Extract parameter names\n",
    "                if 'params' in matched_text:\n",
    "                    param_list = re.findall(r'\\'(.*?)\\'', matched_text)\n",
    "                    param_list = re.findall(r'\\\"(.*?)\\\"', matched_text)\n",
    "                else:\n",
    "                    param_list = [re.findall(r'\\\"(.*?)\\\"', matched_text)[0]]\n",
    "                \n",
    "                # Check for the presence of categorical and numerical variables\n",
    "                has_categorical = any(is_categorical(param) for param in param_list)\n",
    "                has_numerical = any(is_numerical(param) for param in param_list)\n",
    "\n",
    "                # Add a categorical variable if none is present\n",
    "                if not has_categorical and categorical_columns:\n",
    "                    param_list.insert(0, categorical_columns[0])\n",
    "                    has_categorical = True\n",
    "\n",
    "                if len(param_list) < 2:\n",
    "                    return matched_text  # No need to reorder if there are fewer than 2 parameters\n",
    "\n",
    "                first_param = param_list[0]\n",
    "                second_param = param_list[1]\n",
    "\n",
    "                # Check the types of the parameters using the dataframe\n",
    "                #if first_param in df.columns and second_param in df.columns:\n",
    "                if has_categorical and has_numerical:\n",
    "                    if not (is_categorical(first_param) and is_numerical(second_param)):\n",
    "                        param_list[0], param_list[1] = param_list[1], param_list[0]\n",
    "\n",
    "                # Reconstruct the parameters with reordered values\n",
    "                if 'params' in matched_text:\n",
    "                    reordered_params = f\"params = ['{param_list[0]}', '{param_list[1:]}']\"\n",
    "                else:\n",
    "                    reordered_params = f'param = \"{param_list[0]}\"'\n",
    "\n",
    "                return reordered_params.replace('\\'[', ' ').replace(']\\'','')\n",
    "\n",
    "            # Substitute the matches with reordered parameters\n",
    "            modified_script = re.sub(pattern_param, reorder_params, script)\n",
    "\n",
    "            return modified_script\n",
    "\n",
    "    if pattern_multiline.search(script):\n",
    "        # Define a regex pattern to find params and param patterns\n",
    "        pattern_param = re.compile(r'params\\s*=\\s*\\[.*?\\]|param\\s*=\\s*\".*?\"')\n",
    "        \n",
    "        def reorder_params_multiline(match_param):\n",
    "            matched_text = match_param.group(0)  # Get the entire matched text\n",
    "\n",
    "            # Extract parameter names\n",
    "            if 'params' in matched_text:\n",
    "                param_list = re.findall(r'\\'(.*?)\\'', matched_text)\n",
    "                param_list = re.findall(r'\\\"(.*?)\\\"', matched_text)\n",
    "            else:\n",
    "                param_list = [re.findall(r'\\\"(.*?)\\\"', matched_text)[0]]\n",
    "            \n",
    "            # Check for the presence of categorical and numerical variables\n",
    "            has_categorical = any(is_categorical(param) for param in param_list)\n",
    "            has_numerical = any(is_numerical(param) for param in param_list)\n",
    "\n",
    "            # Add a categorical variable if none is present\n",
    "            if not has_categorical and categorical_columns:\n",
    "                param_list.insert(0, categorical_columns[0])\n",
    "                has_categorical = True\n",
    "\n",
    "            if len(param_list) < 2:\n",
    "                return matched_text  # No need to reorder if there are fewer than 2 parameters\n",
    "\n",
    "            first_param = param_list[0]\n",
    "            second_param = param_list[1]\n",
    "\n",
    "            # Check the types of the parameters using the dataframe\n",
    "            #if first_param in df.columns and second_param in df.columns:\n",
    "            if has_categorical and has_numerical:\n",
    "                if not (is_numerical(first_param) and is_categorical(second_param)):\n",
    "                    param_list[0], param_list[1] = param_list[1], param_list[0]\n",
    "\n",
    "            # Reconstruct the parameters with reordered values\n",
    "            if 'params' in matched_text:\n",
    "                reordered_params = f\"params = ['{param_list[0]}', '{param_list[1:]}']\"\n",
    "            else:\n",
    "                reordered_params = f'param = \"{param_list[0]}\"'\n",
    "\n",
    "            return reordered_params.replace('\\'[', ' ').replace(']\\'','')\n",
    "\n",
    "        # Substitute the matches with reordered parameters\n",
    "        modified_script_multiline = re.sub(pattern_param, reorder_params_multiline, script)\n",
    "\n",
    "        return modified_script_multiline\n",
    "\n",
    "        \n",
    "    return script\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the reorder transformation\n",
    "modified_script = original_script#reorder_parameters(original_script, path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_functions = \"\"\"import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sys\n",
    "import  numpy as np\n",
    "from mdvtools.mdvproject import MDVProject\n",
    "from mdvtools.charts.heatmap_plot import HeatmapPlot\n",
    "from mdvtools.charts.histogram_plot import HistogramPlot\n",
    "from mdvtools.charts.dot_plot import DotPlot\n",
    "from mdvtools.charts.box_plot import BoxPlot\n",
    "from mdvtools.charts.scatter_plot_3D import ScatterPlot3D\n",
    "from mdvtools.charts.row_chart import RowChart\n",
    "from mdvtools.charts.scatter_plot import ScatterPlot\n",
    "from mdvtools.charts.abundance_box_plot import AbundanceBoxPlot\n",
    "from mdvtools.charts.stacked_row_plot import StackedRowChart\n",
    "from mdvtools.charts.ring_chart import RingChart\n",
    "from mdvtools.charts.violin_plot import ViolinPlot\n",
    "from mdvtools.charts.multi_line_plot import MultiLinePlot\n",
    "from mdvtools.charts.pie_chart import PieChart\n",
    "\n",
    "import json \\n\n",
    "\\n\n",
    "\n",
    "def load_data(path):\n",
    "    #Load data from the specified CSV file.\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "def convert_plot_to_json(plot):\n",
    "    #Convert plot data to JSON format.\n",
    "    return json.loads(json.dumps(plot.plot_data, indent=2).replace(\"\\\\\\\\\", \"\"))\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into lines\n",
    "lines = modified_script.splitlines()\n",
    "\n",
    "# Find the starting line index\n",
    "start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('def')), None)\n",
    "\n",
    "if start_index is not None:\n",
    "    # Capture all lines starting from the first 'def'\n",
    "    captured_lines = \"\\n\".join(lines[start_index:])\n",
    "    #print(\"Captured part:\\n\", captured_lines)\n",
    "else:\n",
    "    print(\"Pattern not found\")\n",
    "\n",
    "with open(\"temp_code_3.py\", \"w\") as f:\n",
    "    f.write(packages_functions)\n",
    "    f.write(captured_lines)\n",
    "    #f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the prompt and the output of the LLM to the google sheets\n",
    "log_to_google_sheet(sheet, str(context_information_metadata_name), output['query'], prompt_RAG, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created Flask <Flask 'mdvtools.server'>\n",
      "socketio initialized\n",
      "websocket/chat enabled for \n",
      " * Serving Flask app 'mdvtools.server'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5050 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:746\u001b[0m, in \u001b[0;36mBaseWSGIServer.__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_activate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/server.py:136\u001b[0m, in \u001b[0;36mHTTPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[43msocketserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTCPServer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m host, port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py:473\u001b[0m, in \u001b[0;36mTCPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mSOL_SOCKET, socket\u001b[38;5;241m.\u001b[39mSO_REUSEPORT, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mgetsockname()\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 48] Address already in use",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2932\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2931\u001b[0m     glob, loc \u001b[38;5;241m=\u001b[39m (where \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, ))[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m-> 2932\u001b[0m     \u001b[43mpy3compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshell_futures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m status:\n\u001b[1;32m   2936\u001b[0m     \u001b[38;5;66;03m# If the call was made with 0 or None exit status (sys.exit(0)\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m     \u001b[38;5;66;03m# or sys.exit() ), don't bother showing a traceback, as both of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[38;5;66;03m# For other exit status, we show the exception unless\u001b[39;00m\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;66;03m# explicitly silenced, but only in short form.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/utils/py3compat.py:55\u001b[0m, in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m     54\u001b[0m compiler \u001b[38;5;241m=\u001b[39m compiler \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/llm/temp_code_3.py:96\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/llm/temp_code_3.py:93\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m project\u001b[38;5;241m.\u001b[39mset_editable(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/mdvproject.py:835\u001b[0m, in \u001b[0;36mMDVProject.serve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_app\n\u001b[0;32m--> 835\u001b[0m \u001b[43mcreate_app\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MDV/python/mdvtools/server.py:355\u001b[0m, in \u001b[0;36mcreate_app\u001b[0;34m(project, open_browser, port, websocket, use_reloader, app, chat_fn, chat_welcome)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m## nb - uncomment this if not using ProjectBlueprint refactor...\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# app.register_blueprint(project_bp)\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# user_reloader=False, allows the server to work within jupyter\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_reloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py:889\u001b[0m, in \u001b[0;36mFlask.run\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     \u001b[43mrun_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# reset the first request information if the development server\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:1077\u001b[0m, in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWERKZEUG_SERVER_FD\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1077\u001b[0m srv \u001b[38;5;241m=\u001b[39m \u001b[43mmake_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassthrough_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m srv\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mset_inheritable(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:917\u001b[0m, in \u001b[0;36mmake_server\u001b[0;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threaded:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mThreadedWSGIServer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassthrough_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/werkzeug/serving.py:769\u001b[0m, in \u001b[0;36mBaseWSGIServer.__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    764\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOn macOS, try disabling the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirPlay Receiver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m service\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from System Preferences -> General -> AirDrop & Handoff.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    766\u001b[0m                 file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    767\u001b[0m             )\n\u001b[0;32m--> 769\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the saved Python file. This will start a server on localhost:5050, open the browser and display the plot with the server continuing to run in the background.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_code_3.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/magics/execution.py:849\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_timing(run, nruns)\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m             \u001b[38;5;66;03m# regular execution\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m             \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m __name__save\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/magics/execution.py:834\u001b[0m, in \u001b[0;36mExecutionMagics.run.<locals>.run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m():\n\u001b[0;32m--> 834\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_ns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_ns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexit_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_ignore\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2949\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2947\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   2948\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exit_ignore:\n\u001b[0;32m-> 2949\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexception_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   2951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1190\u001b[0m ):\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1083\u001b[0m )\n\u001b[1;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "# Run the saved Python file. This will start a server on localhost:5050, open the browser and display the plot with the server continuing to run in the background.\n",
    "%run temp_code_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvjupyter",
   "language": "python",
   "name": "venvjupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
